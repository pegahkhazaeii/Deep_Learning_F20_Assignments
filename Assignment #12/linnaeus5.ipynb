{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linnaeus5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTHHH1gXFjUE"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import glob"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIwCnAFzF139",
        "outputId": "7359333b-96f2-4bc4-8b1a-4833564d43ca"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbR473TwF5mT",
        "outputId": "c46683c9-d748-4355-d1bc-36502177fe52"
      },
      "source": [
        "!ls \"/content/drive/My Drive/Deep Learning/Linnaeus 5 256X256/train\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "berry  bird  dog  flower  other\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz3iEL3xGB9n"
      },
      "source": [
        "root = \"/content/drive/My Drive/Deep Learning/Linnaeus 5 256X256\"\r\n",
        "files = glob.glob(root+'train/*/*.jpg')\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaYyp3rEGrJN"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from torchvision import transforms\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import pathlib\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import *\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeUndZ1DIOQh"
      },
      "source": [
        "data_transform = transforms.Compose([\r\n",
        "        transforms.RandomRotation(10),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize((0.5,), (0.5,))\r\n",
        "    ])\r\n",
        "\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkDAPYTFcsJQ"
      },
      "source": [
        "train_ds = datasets.ImageFolder(\"/content/drive/My Drive/Deep Learning/Linnaeus 5 256X256/train\",\r\n",
        "                                           transform=data_transform)\r\n",
        "training_generator = torch.utils.data.DataLoader(train_ds,\r\n",
        "                                             batch_size=32, shuffle=True)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PmQM0VhdC_F"
      },
      "source": [
        "validation_ds = datasets.ImageFolder(\"/content/drive/My Drive/Deep Learning/Linnaeus 5 256X256/test\",\r\n",
        "                                           transform=data_transform)\r\n",
        "validation_generator = torch.utils.data.DataLoader(validation_ds,\r\n",
        "                                             batch_size=32, shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rF7GUtVTemQ"
      },
      "source": [
        "opt_functional = {'densenet161':lambda x:optim.Adadelta(x.parameters()),\r\n",
        "                  'googlenet':lambda x:optim.Adadelta(x.parameters())}\r\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpEKxJhMUkCJ"
      },
      "source": [
        "class GoogleNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.googlenet = models.googlenet(pretrained=True)\r\n",
        "        self.fc1 = nn.Linear(1000, 500)\r\n",
        "        self.fc2 = nn.Linear(500, 5)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.googlenet(x)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = nn.Dropout(p=0.3)(x)   \r\n",
        "        x = torch.softmax(self.fc2(x),dim=1)\r\n",
        "        return x\r\n",
        "    \r\n",
        "class Densenet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.densenet161 = models.densenet161(pretrained=True)\r\n",
        "        self.fc1 = nn.Linear(1000, 500)\r\n",
        "        self.fc2 = nn.Linear(500, 5)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.densenet161(x)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = nn.Dropout(p=0.3)(x)   \r\n",
        "        x = torch.softmax(self.fc2(x),dim=1)\r\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZY7ZNm7nPFS"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3LX5-EcUn55",
        "outputId": "6e932b3d-8df0-4973-eb8c-de1f482509d5"
      },
      "source": [
        "\r\n",
        "max_epochs = 10\r\n",
        "\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "\r\n",
        "print(device)\r\n",
        "torch.backends.cudnn.benchmark = True\r\n",
        "cnn_dic = {'densenet161':Densenet(),\r\n",
        "           'googlenet':GoogleNet()}\r\n",
        "mdl_pool = {}\r\n",
        "for name,cnn in cnn_dic.items():\r\n",
        "    print('training ' + name)\r\n",
        "    optimizer = opt_functional[name](cnn)\r\n",
        "    cnn.to(device)\r\n",
        "    train_epoch_loss = [] \r\n",
        "    train_epoch_acc = [] \r\n",
        "    val_epoch_loss = []\r\n",
        "    val_epoch_acc = [] \r\n",
        "    for epoch in range(max_epochs):\r\n",
        "        cnn.train()\r\n",
        "        running_loss = []\r\n",
        "        running_acc = []\r\n",
        "        for local_batch, local_labels in training_generator:\r\n",
        "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\r\n",
        "            optimizer.zero_grad()\r\n",
        "            outputs = cnn(local_batch)\r\n",
        "            loss = loss_function(outputs, local_labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            \r\n",
        "            running_loss += [loss.item()]\r\n",
        "            _, predicted = torch.max(outputs, 1)\r\n",
        "            running_acc += [(predicted == local_labels).sum().item()/training_generator.batch_size]\r\n",
        "        train_epoch_loss += [np.mean(running_loss)]\r\n",
        "        train_epoch_acc += [np.mean(running_acc)]\r\n",
        "        \r\n",
        "        running_loss = []\r\n",
        "        running_acc = []\r\n",
        "        with torch.no_grad():\r\n",
        "            cnn.eval()\r\n",
        "            for local_batch, local_labels in validation_generator:\r\n",
        "                local_batch, local_labels = local_batch.to(device), local_labels.to(device)\r\n",
        "                outputs = cnn(local_batch)\r\n",
        "                loss = loss_function(outputs, local_labels)\r\n",
        "                running_loss += [loss.item()]\r\n",
        "                _, predicted = torch.max(outputs, 1)\r\n",
        "                running_acc += [(predicted == local_labels).sum().item()/validation_generator.batch_size]\r\n",
        "\r\n",
        "        val_epoch_loss += [np.mean(running_loss)]\r\n",
        "        val_epoch_acc += [np.mean(running_acc)]\r\n",
        "        print('\\t[{:d}] loss: {:7.5f} - acc: {:%} - val loss: {:7.5f} - val acc: {:%}'.format(epoch + 1,\r\n",
        "                                                                                            train_epoch_loss[-1],\r\n",
        "                                                                                            train_epoch_acc[-1],\r\n",
        "                                                                                            val_epoch_loss[-1],\r\n",
        "                                                                                            val_epoch_acc[-1]))\r\n",
        "    \r\n",
        "    mdl_pool[name]={}\r\n",
        "    mdl_pool[name]['loss'] = train_epoch_loss\r\n",
        "    mdl_pool[name]['acc'] = train_epoch_acc\r\n",
        "    mdl_pool[name]['val_loss'] = val_epoch_loss\r\n",
        "    mdl_pool[name]['val_acc'] = val_epoch_acc"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "training densenet161\n",
            "\t[1] loss: 1.56604 - acc: 31.881649% - val loss: 1.50122 - val acc: 38.343254%\n",
            "\t[2] loss: 1.56217 - acc: 31.781915% - val loss: 1.55001 - val acc: 30.158730%\n",
            "\t[3] loss: 1.52119 - acc: 35.887633% - val loss: 1.55485 - val acc: 33.482143%\n",
            "\t[4] loss: 1.42779 - acc: 46.193484% - val loss: 1.37246 - val acc: 52.132937%\n",
            "\t[5] loss: 1.38613 - acc: 50.814495% - val loss: 1.39814 - val acc: 49.900794%\n",
            "\t[6] loss: 1.37648 - acc: 51.894947% - val loss: 1.36727 - val acc: 52.876984%\n",
            "\t[7] loss: 1.38046 - acc: 51.612367% - val loss: 1.38438 - val acc: 50.942460%\n",
            "\t[8] loss: 1.36155 - acc: 53.540559% - val loss: 1.30856 - val acc: 58.382937%\n",
            "\t[9] loss: 1.35760 - acc: 53.889628% - val loss: 1.34279 - val acc: 55.753968%\n",
            "\t[10] loss: 1.32663 - acc: 57.247340% - val loss: 1.37660 - val acc: 52.182540%\n",
            "training googlenet\n",
            "\t[1] loss: 1.43653 - acc: 46.476064% - val loss: 1.56713 - val acc: 32.986111%\n",
            "\t[2] loss: 1.51699 - acc: 38.414229% - val loss: 1.56343 - val acc: 33.779762%\n",
            "\t[3] loss: 1.54287 - acc: 35.771277% - val loss: 1.53249 - val acc: 36.607143%\n",
            "\t[4] loss: 1.49374 - acc: 40.824468% - val loss: 1.46018 - val acc: 43.898810%\n",
            "\t[5] loss: 1.46512 - acc: 43.650266% - val loss: 1.41152 - val acc: 48.908730%\n",
            "\t[6] loss: 1.43212 - acc: 46.958112% - val loss: 1.46050 - val acc: 43.998016%\n",
            "\t[7] loss: 1.40825 - acc: 49.484707% - val loss: 1.40571 - val acc: 49.355159%\n",
            "\t[8] loss: 1.41867 - acc: 48.287899% - val loss: 1.42015 - val acc: 47.966270%\n",
            "\t[9] loss: 1.40993 - acc: 49.218750% - val loss: 1.41801 - val acc: 48.065476%\n",
            "\t[10] loss: 1.41603 - acc: 48.387633% - val loss: 1.41498 - val acc: 48.015873%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIfg30p5UsXB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}