{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":18,"outputs":[{"output_type":"stream","text":"/kaggle/input/spooky-author-identification/train.zip\n/kaggle/input/spooky-author-identification/test.zip\n/kaggle/input/spooky-author-identification/sample_submission.zip\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport nltk\nimport string\nimport unidecode\nimport random\nimport torch","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_on_gpu = torch.cuda.is_available()\nif(train_on_gpu):\n    print('Training on GPU!')\nelse: \n    print('No GPU available, training on CPU; consider making n_epochs very small.')","execution_count":20,"outputs":[{"output_type":"stream","text":"No GPU available, training on CPU; consider making n_epochs very small.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/spooky-author-identification/train.zip')\nauthor = train_df[train_df['author'] == 'EAP'][\"text\"]\nauthor[:5]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"0    This process, however, afforded me no means of...\n2    In his left hand was a gold snuff box, from wh...\n6    The astronomer, perhaps, at this point, took r...\n7          The surcingle hung in ribands from my body.\n8    I knew that you could not say to yourself 'ste...\nName: text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = list(author[:100])\ndef joinStrings(text):\n    return ' '.join(string for string in text)\ntext = joinStrings(text)\n# text = [item for sublist in author[:5].values for item in sublist]\nlen(text.split())","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"2802"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(nltk.corpus.stopwords.words('english'))\nexclude = set(string.punctuation) \nlemma = nltk.stem.wordnet.WordNetLemmatizer()\ndef clean(doc):\n        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n        return normalized\ntest_sentence = clean(text).lower().split()","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n            for i in range(len(test_sentence) - 2)]\nchunk_len=len(trigrams)\nprint(trigrams[:3])","execution_count":24,"outputs":[{"output_type":"stream","text":"[(['this', 'process'], 'however'), (['process', 'however'], 'afforded'), (['however', 'afforded'], 'mean')]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab = set(test_sentence)\nvoc_len=len(vocab)\nword_to_ix = {word: i for i, word in enumerate(vocab)}","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp=[]\ntar=[]\nfor context, target in trigrams:\n        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n        inp.append(context_idxs)\n        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n        tar.append(targ)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n        super(RNN, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        \n        self.encoder = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n                          bidirectional=False)\n        self.decoder = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, input, hidden):\n        input = self.encoder(input.view(1, -1))\n        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n        output = self.decoder(output.view(1, -1))\n        return output, hidden\n\n    def init_hidden(self):\n        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(inp, target):\n    hidden = decoder.init_hidden()\n\n    decoder.zero_grad()\n    loss = 0\n    \n    for c in range(chunk_len):\n        output, hidden = decoder(inp[c], hidden)\n        loss += criterion(output, target[c])\n\n    loss.backward()\n    decoder_optimizer.step()\n\n    return loss.data.item() / chunk_len","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time, math\n\ndef time_since(since):\n    s = time.time() - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 300\nprint_every = 100\nplot_every = 10\nhidden_size = 100\nn_layers = 1\nlr = 0.015\n\ndecoder = RNN(voc_len, hidden_size, voc_len, n_layers)\ndecoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\nstart = time.time()\nall_losses = []\nloss_avg = 0\nif(train_on_gpu):\n    decoder\nfor epoch in range(1, n_epochs + 1):\n    loss = train(inp,tar)       \n    loss_avg += loss\n\n    if epoch % print_every == 0:\n        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))\n#         print(evaluate('ge', 200), '\\n')\n\n    if epoch % plot_every == 0:\n        all_losses.append(loss_avg / plot_every)\n        loss_avg = 0","execution_count":30,"outputs":[{"output_type":"stream","text":"[3m 36s (100 16%) 0.0001]\n[7m 4s (200 33%) 0.0001]\n[10m 26s (300 50%) 0.0001]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n%matplotlib inline\n\nplt.figure()\nplt.plot(all_losses)","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7fdbf0fe0dd0>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(prime_str='this process', predict_len=100, temperature=0.8):\n    hidden = decoder.init_hidden()\n\n    for p in range(predict_len):\n        \n        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long)\n        inp = prime_input[-2:] #last two words as input\n        output, hidden = decoder(inp, hidden)\n        \n        # Sample from the network as a multinomial distribution\n        output_dist = output.data.view(-1).div(temperature).exp()\n        top_i = torch.multinomial(output_dist, 1)[0]\n        \n        # Add predicted word to string and use as next input\n        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n        prime_str += \" \" + predicted_word\n#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n\n    return prime_str","execution_count":36,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-36-eda69fa112bf>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-eda69fa112bf>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    hidden = decoder.init_hidden().\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(evaluate('this process', 40, temperature=1))","execution_count":37,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-db81abe0acf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-32-fc837930d50f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(prime_str, predict_len, temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprime_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'this process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}