{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Augmentation-Regularization-Cifar 100.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQZ_crSmUpUX"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD9isBBVU8P9",
        "outputId": "ced330e4-9e75-4732-fbf6-8cedf9beadf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKJTAH4PVFoR",
        "outputId": "eeb7c829-7099-4146-c280-bbfb2c96e072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpbL3EryVJ3r"
      },
      "source": [
        "train=True\n",
        "num_classes = 100\n",
        "weight_decay = 0.0005\n",
        "x_shape = [32,32,3]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0rN46rXVMMA"
      },
      "source": [
        "train=True\n",
        "num_classes = 100\n",
        "weight_decay = 0.0005\n",
        "x_shape = [32,32,3]\n",
        "model = Sequential()\n",
        "weight_decay = weight_decay\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpW8meFGVTSS"
      },
      "source": [
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtHs8Vf3xpkA"
      },
      "source": [
        "## data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2abLeYhVWz1",
        "outputId": "7a09c929-167f-4175-c81a-14462ab2b67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "batch_size = 128\n",
        "maxepoches = 200\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)\n",
        "\n",
        "\n",
        "\n",
        "#optimization details\n",
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# training process in a for loop with learning rate drop every 25 epoches.\n",
        "\n",
        "hist = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    epochs=maxepoches,\n",
        "                    validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)\n",
        "model.save_weights('cifar100vgg.h5')  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-b49fc2b11c7b>:41: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/200\n",
            "390/390 - 33s - loss: 19.2074 - accuracy: 0.0245 - val_loss: 14.7146 - val_accuracy: 0.0154\n",
            "Epoch 2/200\n",
            "390/390 - 32s - loss: 11.1012 - accuracy: 0.0461 - val_loss: 9.8973 - val_accuracy: 0.0187\n",
            "Epoch 3/200\n",
            "390/390 - 32s - loss: 7.2804 - accuracy: 0.0618 - val_loss: 6.8802 - val_accuracy: 0.0331\n",
            "Epoch 4/200\n",
            "390/390 - 32s - loss: 5.5153 - accuracy: 0.0827 - val_loss: 5.1436 - val_accuracy: 0.0716\n",
            "Epoch 5/200\n",
            "390/390 - 32s - loss: 4.6979 - accuracy: 0.0981 - val_loss: 4.5170 - val_accuracy: 0.0988\n",
            "Epoch 6/200\n",
            "390/390 - 32s - loss: 4.3015 - accuracy: 0.1155 - val_loss: 4.1760 - val_accuracy: 0.1277\n",
            "Epoch 7/200\n",
            "390/390 - 32s - loss: 4.0880 - accuracy: 0.1344 - val_loss: 3.9536 - val_accuracy: 0.1510\n",
            "Epoch 8/200\n",
            "390/390 - 32s - loss: 3.9619 - accuracy: 0.1563 - val_loss: 4.0327 - val_accuracy: 0.1525\n",
            "Epoch 9/200\n",
            "390/390 - 32s - loss: 3.8852 - accuracy: 0.1812 - val_loss: 4.1046 - val_accuracy: 0.1694\n",
            "Epoch 10/200\n",
            "390/390 - 32s - loss: 3.8519 - accuracy: 0.2024 - val_loss: 3.7640 - val_accuracy: 0.2362\n",
            "Epoch 11/200\n",
            "390/390 - 32s - loss: 3.8098 - accuracy: 0.2244 - val_loss: 3.7012 - val_accuracy: 0.2556\n",
            "Epoch 12/200\n",
            "390/390 - 31s - loss: 3.7839 - accuracy: 0.2415 - val_loss: 3.7427 - val_accuracy: 0.2618\n",
            "Epoch 13/200\n",
            "390/390 - 31s - loss: 3.7823 - accuracy: 0.2550 - val_loss: 3.7917 - val_accuracy: 0.2584\n",
            "Epoch 14/200\n",
            "390/390 - 32s - loss: 3.7860 - accuracy: 0.2676 - val_loss: 3.6136 - val_accuracy: 0.3093\n",
            "Epoch 15/200\n",
            "390/390 - 32s - loss: 3.8083 - accuracy: 0.2775 - val_loss: 4.1194 - val_accuracy: 0.2413\n",
            "Epoch 16/200\n",
            "390/390 - 31s - loss: 3.8343 - accuracy: 0.2829 - val_loss: 3.9188 - val_accuracy: 0.2869\n",
            "Epoch 17/200\n",
            "390/390 - 31s - loss: 3.8302 - accuracy: 0.2947 - val_loss: 4.0163 - val_accuracy: 0.2894\n",
            "Epoch 18/200\n",
            "390/390 - 31s - loss: 3.8639 - accuracy: 0.2990 - val_loss: 4.0030 - val_accuracy: 0.2954\n",
            "Epoch 19/200\n",
            "390/390 - 31s - loss: 3.8596 - accuracy: 0.3119 - val_loss: 3.7195 - val_accuracy: 0.3379\n",
            "Epoch 20/200\n",
            "390/390 - 31s - loss: 3.8851 - accuracy: 0.3143 - val_loss: 3.8626 - val_accuracy: 0.3221\n",
            "Epoch 21/200\n",
            "390/390 - 31s - loss: 3.5557 - accuracy: 0.3703 - val_loss: 3.4142 - val_accuracy: 0.3911\n",
            "Epoch 22/200\n",
            "390/390 - 31s - loss: 3.3926 - accuracy: 0.3863 - val_loss: 3.3097 - val_accuracy: 0.4095\n",
            "Epoch 23/200\n",
            "390/390 - 31s - loss: 3.3500 - accuracy: 0.3909 - val_loss: 3.5468 - val_accuracy: 0.3676\n",
            "Epoch 24/200\n",
            "390/390 - 31s - loss: 3.3314 - accuracy: 0.3954 - val_loss: 3.2932 - val_accuracy: 0.4141\n",
            "Epoch 25/200\n",
            "390/390 - 31s - loss: 3.3508 - accuracy: 0.3958 - val_loss: 3.3130 - val_accuracy: 0.4102\n",
            "Epoch 26/200\n",
            "390/390 - 31s - loss: 3.3503 - accuracy: 0.3996 - val_loss: 3.4619 - val_accuracy: 0.3858\n",
            "Epoch 27/200\n",
            "390/390 - 31s - loss: 3.3424 - accuracy: 0.4099 - val_loss: 3.8621 - val_accuracy: 0.3394\n",
            "Epoch 28/200\n",
            "390/390 - 31s - loss: 3.3571 - accuracy: 0.4124 - val_loss: 3.2723 - val_accuracy: 0.4290\n",
            "Epoch 29/200\n",
            "390/390 - 31s - loss: 3.3624 - accuracy: 0.4136 - val_loss: 3.8786 - val_accuracy: 0.3734\n",
            "Epoch 30/200\n",
            "390/390 - 31s - loss: 3.3574 - accuracy: 0.4211 - val_loss: 3.3269 - val_accuracy: 0.4317\n",
            "Epoch 31/200\n",
            "390/390 - 31s - loss: 3.3825 - accuracy: 0.4199 - val_loss: 3.3742 - val_accuracy: 0.4364\n",
            "Epoch 32/200\n",
            "390/390 - 31s - loss: 3.3875 - accuracy: 0.4232 - val_loss: 3.7282 - val_accuracy: 0.3695\n",
            "Epoch 33/200\n",
            "390/390 - 31s - loss: 3.3737 - accuracy: 0.4290 - val_loss: 3.2566 - val_accuracy: 0.4529\n",
            "Epoch 34/200\n",
            "390/390 - 31s - loss: 3.3746 - accuracy: 0.4329 - val_loss: 3.5618 - val_accuracy: 0.4082\n",
            "Epoch 35/200\n",
            "390/390 - 32s - loss: 3.3926 - accuracy: 0.4334 - val_loss: 3.4694 - val_accuracy: 0.4263\n",
            "Epoch 36/200\n",
            "390/390 - 32s - loss: 3.4000 - accuracy: 0.4374 - val_loss: 3.4111 - val_accuracy: 0.4420\n",
            "Epoch 37/200\n",
            "390/390 - 32s - loss: 3.4057 - accuracy: 0.4409 - val_loss: 3.4392 - val_accuracy: 0.4431\n",
            "Epoch 38/200\n",
            "390/390 - 32s - loss: 3.4110 - accuracy: 0.4419 - val_loss: 3.6979 - val_accuracy: 0.4101\n",
            "Epoch 39/200\n",
            "390/390 - 32s - loss: 3.4120 - accuracy: 0.4447 - val_loss: 3.5920 - val_accuracy: 0.4219\n",
            "Epoch 40/200\n",
            "390/390 - 32s - loss: 3.4158 - accuracy: 0.4477 - val_loss: 3.8091 - val_accuracy: 0.4014\n",
            "Epoch 41/200\n",
            "390/390 - 32s - loss: 3.1337 - accuracy: 0.4991 - val_loss: 3.0066 - val_accuracy: 0.5198\n",
            "Epoch 42/200\n",
            "390/390 - 32s - loss: 2.9905 - accuracy: 0.5136 - val_loss: 2.9216 - val_accuracy: 0.5234\n",
            "Epoch 43/200\n",
            "390/390 - 32s - loss: 2.9163 - accuracy: 0.5154 - val_loss: 2.9392 - val_accuracy: 0.5173\n",
            "Epoch 44/200\n",
            "390/390 - 32s - loss: 2.8937 - accuracy: 0.5176 - val_loss: 2.8760 - val_accuracy: 0.5231\n",
            "Epoch 45/200\n",
            "390/390 - 32s - loss: 2.8759 - accuracy: 0.5184 - val_loss: 3.1021 - val_accuracy: 0.4868\n",
            "Epoch 46/200\n",
            "390/390 - 32s - loss: 2.8548 - accuracy: 0.5190 - val_loss: 2.8546 - val_accuracy: 0.5262\n",
            "Epoch 47/200\n",
            "390/390 - 32s - loss: 2.8446 - accuracy: 0.5263 - val_loss: 3.0368 - val_accuracy: 0.4960\n",
            "Epoch 48/200\n",
            "390/390 - 32s - loss: 2.8500 - accuracy: 0.5257 - val_loss: 2.8875 - val_accuracy: 0.5204\n",
            "Epoch 49/200\n",
            "390/390 - 32s - loss: 2.8470 - accuracy: 0.5271 - val_loss: 2.9561 - val_accuracy: 0.5161\n",
            "Epoch 50/200\n",
            "390/390 - 33s - loss: 2.8549 - accuracy: 0.5285 - val_loss: 2.8497 - val_accuracy: 0.5334\n",
            "Epoch 51/200\n",
            "390/390 - 32s - loss: 2.8564 - accuracy: 0.5276 - val_loss: 2.8730 - val_accuracy: 0.5389\n",
            "Epoch 52/200\n",
            "390/390 - 32s - loss: 2.8579 - accuracy: 0.5301 - val_loss: 3.0210 - val_accuracy: 0.5082\n",
            "Epoch 53/200\n",
            "390/390 - 32s - loss: 2.8678 - accuracy: 0.5315 - val_loss: 2.8712 - val_accuracy: 0.5396\n",
            "Epoch 54/200\n",
            "390/390 - 32s - loss: 2.8760 - accuracy: 0.5302 - val_loss: 2.9464 - val_accuracy: 0.5291\n",
            "Epoch 55/200\n",
            "390/390 - 32s - loss: 2.8628 - accuracy: 0.5364 - val_loss: 3.1163 - val_accuracy: 0.5021\n",
            "Epoch 56/200\n",
            "390/390 - 32s - loss: 2.8809 - accuracy: 0.5360 - val_loss: 3.0515 - val_accuracy: 0.5168\n",
            "Epoch 57/200\n",
            "390/390 - 32s - loss: 2.8823 - accuracy: 0.5372 - val_loss: 3.0981 - val_accuracy: 0.5105\n",
            "Epoch 58/200\n",
            "390/390 - 32s - loss: 2.8868 - accuracy: 0.5391 - val_loss: 3.0694 - val_accuracy: 0.5101\n",
            "Epoch 59/200\n",
            "390/390 - 32s - loss: 2.8758 - accuracy: 0.5422 - val_loss: 2.9400 - val_accuracy: 0.5374\n",
            "Epoch 60/200\n",
            "390/390 - 32s - loss: 2.8803 - accuracy: 0.5436 - val_loss: 3.4476 - val_accuracy: 0.4607\n",
            "Epoch 61/200\n",
            "390/390 - 32s - loss: 2.6698 - accuracy: 0.5882 - val_loss: 2.6040 - val_accuracy: 0.6005\n",
            "Epoch 62/200\n",
            "390/390 - 32s - loss: 2.5537 - accuracy: 0.6035 - val_loss: 2.6763 - val_accuracy: 0.5830\n",
            "Epoch 63/200\n",
            "390/390 - 32s - loss: 2.4937 - accuracy: 0.6115 - val_loss: 2.5662 - val_accuracy: 0.5958\n",
            "Epoch 64/200\n",
            "390/390 - 32s - loss: 2.4519 - accuracy: 0.6120 - val_loss: 2.6689 - val_accuracy: 0.5776\n",
            "Epoch 65/200\n",
            "390/390 - 32s - loss: 2.4335 - accuracy: 0.6158 - val_loss: 2.6007 - val_accuracy: 0.5863\n",
            "Epoch 66/200\n",
            "390/390 - 32s - loss: 2.4075 - accuracy: 0.6150 - val_loss: 2.5313 - val_accuracy: 0.6001\n",
            "Epoch 67/200\n",
            "390/390 - 32s - loss: 2.3972 - accuracy: 0.6151 - val_loss: 2.5436 - val_accuracy: 0.5882\n",
            "Epoch 68/200\n",
            "390/390 - 32s - loss: 2.3976 - accuracy: 0.6146 - val_loss: 2.5799 - val_accuracy: 0.5857\n",
            "Epoch 69/200\n",
            "390/390 - 32s - loss: 2.3800 - accuracy: 0.6172 - val_loss: 2.5230 - val_accuracy: 0.5920\n",
            "Epoch 70/200\n",
            "390/390 - 31s - loss: 2.3799 - accuracy: 0.6168 - val_loss: 2.5980 - val_accuracy: 0.5808\n",
            "Epoch 71/200\n",
            "390/390 - 31s - loss: 2.3735 - accuracy: 0.6185 - val_loss: 2.5781 - val_accuracy: 0.5815\n",
            "Epoch 72/200\n",
            "390/390 - 31s - loss: 2.3715 - accuracy: 0.6197 - val_loss: 2.6217 - val_accuracy: 0.5761\n",
            "Epoch 73/200\n",
            "390/390 - 31s - loss: 2.3761 - accuracy: 0.6199 - val_loss: 2.5577 - val_accuracy: 0.5884\n",
            "Epoch 74/200\n",
            "390/390 - 31s - loss: 2.3571 - accuracy: 0.6244 - val_loss: 2.5865 - val_accuracy: 0.5841\n",
            "Epoch 75/200\n",
            "390/390 - 31s - loss: 2.3781 - accuracy: 0.6198 - val_loss: 2.6263 - val_accuracy: 0.5868\n",
            "Epoch 76/200\n",
            "390/390 - 31s - loss: 2.3768 - accuracy: 0.6225 - val_loss: 2.7613 - val_accuracy: 0.5623\n",
            "Epoch 77/200\n",
            "390/390 - 31s - loss: 2.3705 - accuracy: 0.6264 - val_loss: 2.5752 - val_accuracy: 0.5930\n",
            "Epoch 78/200\n",
            "390/390 - 31s - loss: 2.3742 - accuracy: 0.6263 - val_loss: 2.5327 - val_accuracy: 0.6007\n",
            "Epoch 79/200\n",
            "390/390 - 31s - loss: 2.3640 - accuracy: 0.6268 - val_loss: 2.6790 - val_accuracy: 0.5797\n",
            "Epoch 80/200\n",
            "390/390 - 31s - loss: 2.3678 - accuracy: 0.6271 - val_loss: 2.5748 - val_accuracy: 0.5959\n",
            "Epoch 81/200\n",
            "390/390 - 31s - loss: 2.2076 - accuracy: 0.6660 - val_loss: 2.4445 - val_accuracy: 0.6227\n",
            "Epoch 82/200\n",
            "390/390 - 31s - loss: 2.1235 - accuracy: 0.6793 - val_loss: 2.3976 - val_accuracy: 0.6259\n",
            "Epoch 83/200\n",
            "390/390 - 31s - loss: 2.0842 - accuracy: 0.6852 - val_loss: 2.2208 - val_accuracy: 0.6606\n",
            "Epoch 84/200\n",
            "390/390 - 31s - loss: 2.0541 - accuracy: 0.6874 - val_loss: 2.3834 - val_accuracy: 0.6237\n",
            "Epoch 85/200\n",
            "390/390 - 31s - loss: 2.0377 - accuracy: 0.6896 - val_loss: 2.3193 - val_accuracy: 0.6397\n",
            "Epoch 86/200\n",
            "390/390 - 31s - loss: 2.0190 - accuracy: 0.6917 - val_loss: 2.4037 - val_accuracy: 0.6175\n",
            "Epoch 87/200\n",
            "390/390 - 31s - loss: 2.0004 - accuracy: 0.6952 - val_loss: 2.3895 - val_accuracy: 0.6184\n",
            "Epoch 88/200\n",
            "390/390 - 31s - loss: 1.9862 - accuracy: 0.6953 - val_loss: 2.4189 - val_accuracy: 0.6143\n",
            "Epoch 89/200\n",
            "390/390 - 31s - loss: 1.9698 - accuracy: 0.6967 - val_loss: 2.2835 - val_accuracy: 0.6412\n",
            "Epoch 90/200\n",
            "390/390 - 31s - loss: 1.9678 - accuracy: 0.6974 - val_loss: 2.3488 - val_accuracy: 0.6197\n",
            "Epoch 91/200\n",
            "390/390 - 31s - loss: 1.9519 - accuracy: 0.6966 - val_loss: 2.2726 - val_accuracy: 0.6432\n",
            "Epoch 92/200\n",
            "390/390 - 31s - loss: 1.9500 - accuracy: 0.6965 - val_loss: 2.2737 - val_accuracy: 0.6361\n",
            "Epoch 93/200\n",
            "390/390 - 31s - loss: 1.9429 - accuracy: 0.6980 - val_loss: 2.3073 - val_accuracy: 0.6336\n",
            "Epoch 94/200\n",
            "390/390 - 31s - loss: 1.9368 - accuracy: 0.6991 - val_loss: 2.3544 - val_accuracy: 0.6275\n",
            "Epoch 95/200\n",
            "390/390 - 31s - loss: 1.9328 - accuracy: 0.7004 - val_loss: 2.3646 - val_accuracy: 0.6341\n",
            "Epoch 96/200\n",
            "390/390 - 31s - loss: 1.9350 - accuracy: 0.6989 - val_loss: 2.3343 - val_accuracy: 0.6299\n",
            "Epoch 97/200\n",
            "390/390 - 31s - loss: 1.9432 - accuracy: 0.6962 - val_loss: 2.3375 - val_accuracy: 0.6257\n",
            "Epoch 98/200\n",
            "390/390 - 32s - loss: 1.9194 - accuracy: 0.7035 - val_loss: 2.3203 - val_accuracy: 0.6314\n",
            "Epoch 99/200\n",
            "390/390 - 32s - loss: 1.9230 - accuracy: 0.7015 - val_loss: 2.3456 - val_accuracy: 0.6267\n",
            "Epoch 100/200\n",
            "390/390 - 31s - loss: 1.9252 - accuracy: 0.7009 - val_loss: 2.4121 - val_accuracy: 0.6156\n",
            "Epoch 101/200\n",
            "390/390 - 31s - loss: 1.8021 - accuracy: 0.7330 - val_loss: 2.3035 - val_accuracy: 0.6364\n",
            "Epoch 102/200\n",
            "390/390 - 31s - loss: 1.7379 - accuracy: 0.7474 - val_loss: 2.1624 - val_accuracy: 0.6658\n",
            "Epoch 103/200\n",
            "390/390 - 31s - loss: 1.7152 - accuracy: 0.7489 - val_loss: 2.2013 - val_accuracy: 0.6544\n",
            "Epoch 104/200\n",
            "390/390 - 31s - loss: 1.6856 - accuracy: 0.7521 - val_loss: 2.1979 - val_accuracy: 0.6554\n",
            "Epoch 105/200\n",
            "390/390 - 31s - loss: 1.6769 - accuracy: 0.7547 - val_loss: 2.3500 - val_accuracy: 0.6351\n",
            "Epoch 106/200\n",
            "390/390 - 31s - loss: 1.6534 - accuracy: 0.7595 - val_loss: 2.3165 - val_accuracy: 0.6406\n",
            "Epoch 107/200\n",
            "390/390 - 31s - loss: 1.6434 - accuracy: 0.7590 - val_loss: 2.1503 - val_accuracy: 0.6653\n",
            "Epoch 108/200\n",
            "390/390 - 31s - loss: 1.6248 - accuracy: 0.7642 - val_loss: 2.1344 - val_accuracy: 0.6664\n",
            "Epoch 109/200\n",
            "390/390 - 31s - loss: 1.6178 - accuracy: 0.7619 - val_loss: 2.1862 - val_accuracy: 0.6554\n",
            "Epoch 110/200\n",
            "390/390 - 31s - loss: 1.6064 - accuracy: 0.7635 - val_loss: 2.2409 - val_accuracy: 0.6503\n",
            "Epoch 111/200\n",
            "390/390 - 31s - loss: 1.6021 - accuracy: 0.7652 - val_loss: 2.2827 - val_accuracy: 0.6413\n",
            "Epoch 112/200\n",
            "390/390 - 31s - loss: 1.5887 - accuracy: 0.7667 - val_loss: 2.1561 - val_accuracy: 0.6620\n",
            "Epoch 113/200\n",
            "390/390 - 31s - loss: 1.5860 - accuracy: 0.7653 - val_loss: 2.1313 - val_accuracy: 0.6671\n",
            "Epoch 114/200\n",
            "390/390 - 31s - loss: 1.5767 - accuracy: 0.7663 - val_loss: 2.1517 - val_accuracy: 0.6606\n",
            "Epoch 115/200\n",
            "390/390 - 31s - loss: 1.5656 - accuracy: 0.7692 - val_loss: 2.1293 - val_accuracy: 0.6625\n",
            "Epoch 116/200\n",
            "390/390 - 31s - loss: 1.5575 - accuracy: 0.7713 - val_loss: 2.1583 - val_accuracy: 0.6673\n",
            "Epoch 117/200\n",
            "390/390 - 31s - loss: 1.5550 - accuracy: 0.7708 - val_loss: 2.2382 - val_accuracy: 0.6455\n",
            "Epoch 118/200\n",
            "390/390 - 31s - loss: 1.5469 - accuracy: 0.7713 - val_loss: 2.1889 - val_accuracy: 0.6563\n",
            "Epoch 119/200\n",
            "390/390 - 31s - loss: 1.5486 - accuracy: 0.7690 - val_loss: 2.1864 - val_accuracy: 0.6541\n",
            "Epoch 120/200\n",
            "390/390 - 31s - loss: 1.5347 - accuracy: 0.7745 - val_loss: 2.2095 - val_accuracy: 0.6518\n",
            "Epoch 121/200\n",
            "390/390 - 31s - loss: 1.4635 - accuracy: 0.7936 - val_loss: 2.0922 - val_accuracy: 0.6737\n",
            "Epoch 122/200\n",
            "390/390 - 31s - loss: 1.4276 - accuracy: 0.8012 - val_loss: 2.0499 - val_accuracy: 0.6806\n",
            "Epoch 123/200\n",
            "390/390 - 31s - loss: 1.3995 - accuracy: 0.8073 - val_loss: 2.1469 - val_accuracy: 0.6667\n",
            "Epoch 124/200\n",
            "390/390 - 31s - loss: 1.3871 - accuracy: 0.8088 - val_loss: 2.1365 - val_accuracy: 0.6652\n",
            "Epoch 125/200\n",
            "390/390 - 31s - loss: 1.3714 - accuracy: 0.8118 - val_loss: 2.0448 - val_accuracy: 0.6874\n",
            "Epoch 126/200\n",
            "390/390 - 31s - loss: 1.3639 - accuracy: 0.8118 - val_loss: 2.1014 - val_accuracy: 0.6774\n",
            "Epoch 127/200\n",
            "390/390 - 31s - loss: 1.3386 - accuracy: 0.8190 - val_loss: 2.1487 - val_accuracy: 0.6692\n",
            "Epoch 128/200\n",
            "390/390 - 31s - loss: 1.3355 - accuracy: 0.8160 - val_loss: 2.1904 - val_accuracy: 0.6609\n",
            "Epoch 129/200\n",
            "390/390 - 31s - loss: 1.3324 - accuracy: 0.8190 - val_loss: 2.1661 - val_accuracy: 0.6640\n",
            "Epoch 130/200\n",
            "390/390 - 31s - loss: 1.3184 - accuracy: 0.8199 - val_loss: 2.1004 - val_accuracy: 0.6774\n",
            "Epoch 131/200\n",
            "390/390 - 31s - loss: 1.3056 - accuracy: 0.8222 - val_loss: 2.1679 - val_accuracy: 0.6639\n",
            "Epoch 132/200\n",
            "390/390 - 31s - loss: 1.2970 - accuracy: 0.8246 - val_loss: 2.1269 - val_accuracy: 0.6715\n",
            "Epoch 133/200\n",
            "390/390 - 31s - loss: 1.2956 - accuracy: 0.8221 - val_loss: 2.1743 - val_accuracy: 0.6629\n",
            "Epoch 134/200\n",
            "390/390 - 31s - loss: 1.2874 - accuracy: 0.8238 - val_loss: 2.1832 - val_accuracy: 0.6657\n",
            "Epoch 135/200\n",
            "390/390 - 31s - loss: 1.2845 - accuracy: 0.8253 - val_loss: 2.2134 - val_accuracy: 0.6601\n",
            "Epoch 136/200\n",
            "390/390 - 31s - loss: 1.2740 - accuracy: 0.8260 - val_loss: 2.2057 - val_accuracy: 0.6613\n",
            "Epoch 137/200\n",
            "390/390 - 32s - loss: 1.2648 - accuracy: 0.8278 - val_loss: 2.1676 - val_accuracy: 0.6633\n",
            "Epoch 138/200\n",
            "390/390 - 32s - loss: 1.2714 - accuracy: 0.8259 - val_loss: 2.1859 - val_accuracy: 0.6637\n",
            "Epoch 139/200\n",
            "390/390 - 31s - loss: 1.2613 - accuracy: 0.8264 - val_loss: 2.1508 - val_accuracy: 0.6675\n",
            "Epoch 140/200\n",
            "390/390 - 31s - loss: 1.2539 - accuracy: 0.8297 - val_loss: 2.2139 - val_accuracy: 0.6561\n",
            "Epoch 141/200\n",
            "390/390 - 32s - loss: 1.2070 - accuracy: 0.8420 - val_loss: 2.0854 - val_accuracy: 0.6769\n",
            "Epoch 142/200\n",
            "390/390 - 32s - loss: 1.1857 - accuracy: 0.8451 - val_loss: 2.1598 - val_accuracy: 0.6690\n",
            "Epoch 143/200\n",
            "390/390 - 32s - loss: 1.1693 - accuracy: 0.8501 - val_loss: 2.1043 - val_accuracy: 0.6802\n",
            "Epoch 144/200\n",
            "390/390 - 32s - loss: 1.1587 - accuracy: 0.8529 - val_loss: 2.1031 - val_accuracy: 0.6826\n",
            "Epoch 145/200\n",
            "390/390 - 32s - loss: 1.1563 - accuracy: 0.8519 - val_loss: 2.1008 - val_accuracy: 0.6782\n",
            "Epoch 146/200\n",
            "390/390 - 32s - loss: 1.1432 - accuracy: 0.8545 - val_loss: 2.1994 - val_accuracy: 0.6682\n",
            "Epoch 147/200\n",
            "390/390 - 32s - loss: 1.1259 - accuracy: 0.8601 - val_loss: 2.1352 - val_accuracy: 0.6756\n",
            "Epoch 148/200\n",
            "390/390 - 32s - loss: 1.1245 - accuracy: 0.8605 - val_loss: 2.1543 - val_accuracy: 0.6704\n",
            "Epoch 149/200\n",
            "390/390 - 32s - loss: 1.1218 - accuracy: 0.8597 - val_loss: 2.1799 - val_accuracy: 0.6702\n",
            "Epoch 150/200\n",
            "390/390 - 32s - loss: 1.1109 - accuracy: 0.8616 - val_loss: 2.1802 - val_accuracy: 0.6661\n",
            "Epoch 151/200\n",
            "390/390 - 32s - loss: 1.0968 - accuracy: 0.8652 - val_loss: 2.2113 - val_accuracy: 0.6656\n",
            "Epoch 152/200\n",
            "390/390 - 32s - loss: 1.1006 - accuracy: 0.8625 - val_loss: 2.1576 - val_accuracy: 0.6746\n",
            "Epoch 153/200\n",
            "390/390 - 32s - loss: 1.0981 - accuracy: 0.8634 - val_loss: 2.1737 - val_accuracy: 0.6706\n",
            "Epoch 154/200\n",
            "390/390 - 32s - loss: 1.0877 - accuracy: 0.8658 - val_loss: 2.1190 - val_accuracy: 0.6810\n",
            "Epoch 155/200\n",
            "390/390 - 32s - loss: 1.0879 - accuracy: 0.8643 - val_loss: 2.1523 - val_accuracy: 0.6769\n",
            "Epoch 156/200\n",
            "390/390 - 32s - loss: 1.0756 - accuracy: 0.8693 - val_loss: 2.2219 - val_accuracy: 0.6667\n",
            "Epoch 157/200\n",
            "390/390 - 33s - loss: 1.0720 - accuracy: 0.8676 - val_loss: 2.1678 - val_accuracy: 0.6723\n",
            "Epoch 158/200\n",
            "390/390 - 32s - loss: 1.0692 - accuracy: 0.8686 - val_loss: 2.1823 - val_accuracy: 0.6708\n",
            "Epoch 159/200\n",
            "390/390 - 32s - loss: 1.0681 - accuracy: 0.8678 - val_loss: 2.1305 - val_accuracy: 0.6791\n",
            "Epoch 160/200\n",
            "390/390 - 32s - loss: 1.0599 - accuracy: 0.8680 - val_loss: 2.2294 - val_accuracy: 0.6655\n",
            "Epoch 161/200\n",
            "390/390 - 32s - loss: 1.0340 - accuracy: 0.8766 - val_loss: 2.1573 - val_accuracy: 0.6778\n",
            "Epoch 162/200\n",
            "390/390 - 32s - loss: 1.0216 - accuracy: 0.8792 - val_loss: 2.1687 - val_accuracy: 0.6772\n",
            "Epoch 163/200\n",
            "390/390 - 32s - loss: 1.0168 - accuracy: 0.8818 - val_loss: 2.1442 - val_accuracy: 0.6768\n",
            "Epoch 164/200\n",
            "390/390 - 32s - loss: 1.0164 - accuracy: 0.8795 - val_loss: 2.1557 - val_accuracy: 0.6784\n",
            "Epoch 165/200\n",
            "390/390 - 32s - loss: 1.0009 - accuracy: 0.8837 - val_loss: 2.1408 - val_accuracy: 0.6805\n",
            "Epoch 166/200\n",
            "390/390 - 32s - loss: 1.0003 - accuracy: 0.8850 - val_loss: 2.1428 - val_accuracy: 0.6831\n",
            "Epoch 167/200\n",
            "390/390 - 32s - loss: 0.9996 - accuracy: 0.8848 - val_loss: 2.1412 - val_accuracy: 0.6808\n",
            "Epoch 168/200\n",
            "390/390 - 32s - loss: 0.9885 - accuracy: 0.8870 - val_loss: 2.1466 - val_accuracy: 0.6815\n",
            "Epoch 169/200\n",
            "390/390 - 32s - loss: 0.9910 - accuracy: 0.8856 - val_loss: 2.1600 - val_accuracy: 0.6768\n",
            "Epoch 170/200\n",
            "390/390 - 32s - loss: 0.9791 - accuracy: 0.8880 - val_loss: 2.1535 - val_accuracy: 0.6810\n",
            "Epoch 171/200\n",
            "390/390 - 32s - loss: 0.9764 - accuracy: 0.8908 - val_loss: 2.1443 - val_accuracy: 0.6809\n",
            "Epoch 172/200\n",
            "390/390 - 33s - loss: 0.9751 - accuracy: 0.8895 - val_loss: 2.1942 - val_accuracy: 0.6753\n",
            "Epoch 173/200\n",
            "390/390 - 33s - loss: 0.9709 - accuracy: 0.8894 - val_loss: 2.1573 - val_accuracy: 0.6783\n",
            "Epoch 174/200\n",
            "390/390 - 32s - loss: 0.9732 - accuracy: 0.8894 - val_loss: 2.2194 - val_accuracy: 0.6733\n",
            "Epoch 175/200\n",
            "390/390 - 33s - loss: 0.9662 - accuracy: 0.8900 - val_loss: 2.2214 - val_accuracy: 0.6726\n",
            "Epoch 176/200\n",
            "390/390 - 32s - loss: 0.9585 - accuracy: 0.8939 - val_loss: 2.2125 - val_accuracy: 0.6762\n",
            "Epoch 177/200\n",
            "390/390 - 33s - loss: 0.9631 - accuracy: 0.8903 - val_loss: 2.1298 - val_accuracy: 0.6849\n",
            "Epoch 178/200\n",
            "390/390 - 32s - loss: 0.9546 - accuracy: 0.8925 - val_loss: 2.1652 - val_accuracy: 0.6813\n",
            "Epoch 179/200\n",
            "390/390 - 32s - loss: 0.9531 - accuracy: 0.8916 - val_loss: 2.1958 - val_accuracy: 0.6768\n",
            "Epoch 180/200\n",
            "390/390 - 33s - loss: 0.9549 - accuracy: 0.8914 - val_loss: 2.2073 - val_accuracy: 0.6717\n",
            "Epoch 181/200\n",
            "390/390 - 33s - loss: 0.9420 - accuracy: 0.8953 - val_loss: 2.1879 - val_accuracy: 0.6778\n",
            "Epoch 182/200\n",
            "390/390 - 32s - loss: 0.9344 - accuracy: 0.8979 - val_loss: 2.1642 - val_accuracy: 0.6806\n",
            "Epoch 183/200\n",
            "390/390 - 32s - loss: 0.9345 - accuracy: 0.8975 - val_loss: 2.1753 - val_accuracy: 0.6814\n",
            "Epoch 184/200\n",
            "390/390 - 32s - loss: 0.9266 - accuracy: 0.8995 - val_loss: 2.1642 - val_accuracy: 0.6820\n",
            "Epoch 185/200\n",
            "390/390 - 32s - loss: 0.9247 - accuracy: 0.8998 - val_loss: 2.1905 - val_accuracy: 0.6770\n",
            "Epoch 186/200\n",
            "390/390 - 33s - loss: 0.9222 - accuracy: 0.9011 - val_loss: 2.2009 - val_accuracy: 0.6789\n",
            "Epoch 187/200\n",
            "390/390 - 33s - loss: 0.9232 - accuracy: 0.8987 - val_loss: 2.1457 - val_accuracy: 0.6862\n",
            "Epoch 188/200\n",
            "390/390 - 32s - loss: 0.9210 - accuracy: 0.9012 - val_loss: 2.1928 - val_accuracy: 0.6788\n",
            "Epoch 189/200\n",
            "390/390 - 33s - loss: 0.9132 - accuracy: 0.9021 - val_loss: 2.1857 - val_accuracy: 0.6792\n",
            "Epoch 190/200\n",
            "390/390 - 32s - loss: 0.9139 - accuracy: 0.9019 - val_loss: 2.1685 - val_accuracy: 0.6858\n",
            "Epoch 191/200\n",
            "390/390 - 32s - loss: 0.9157 - accuracy: 0.9003 - val_loss: 2.1791 - val_accuracy: 0.6803\n",
            "Epoch 192/200\n",
            "390/390 - 32s - loss: 0.9009 - accuracy: 0.9059 - val_loss: 2.1787 - val_accuracy: 0.6794\n",
            "Epoch 193/200\n",
            "390/390 - 32s - loss: 0.9067 - accuracy: 0.9040 - val_loss: 2.2056 - val_accuracy: 0.6745\n",
            "Epoch 194/200\n",
            "390/390 - 32s - loss: 0.9051 - accuracy: 0.9042 - val_loss: 2.1731 - val_accuracy: 0.6807\n",
            "Epoch 195/200\n",
            "390/390 - 32s - loss: 0.9009 - accuracy: 0.9044 - val_loss: 2.1667 - val_accuracy: 0.6835\n",
            "Epoch 196/200\n",
            "390/390 - 33s - loss: 0.9046 - accuracy: 0.9033 - val_loss: 2.1639 - val_accuracy: 0.6823\n",
            "Epoch 197/200\n",
            "390/390 - 33s - loss: 0.8961 - accuracy: 0.9044 - val_loss: 2.1897 - val_accuracy: 0.6780\n",
            "Epoch 198/200\n",
            "390/390 - 32s - loss: 0.8976 - accuracy: 0.9045 - val_loss: 2.1847 - val_accuracy: 0.6789\n",
            "Epoch 199/200\n",
            "390/390 - 32s - loss: 0.8999 - accuracy: 0.9047 - val_loss: 2.1874 - val_accuracy: 0.6763\n",
            "Epoch 200/200\n",
            "390/390 - 32s - loss: 0.8925 - accuracy: 0.9072 - val_loss: 2.1922 - val_accuracy: 0.6787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUaFK-Pdx4ov"
      },
      "source": [
        "train=True\n",
        "num_classes = 100\n",
        "weight_decay = 0.0005\n",
        "x_shape = [32,32,3]\n",
        "model = Sequential()\n",
        "weight_decay = weight_decay\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXwMpFUQy1Vz"
      },
      "source": [
        "## L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njNZ5q3Sx6MB"
      },
      "source": [
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEl2oEibyAoV"
      },
      "source": [
        "_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "batch_size = 128\n",
        "maxepoches = 200\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrhaJRsIyGE3"
      },
      "source": [
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHBI5qfeyM5Q",
        "outputId": "18e40155-28bf-4d14-c2ad-e5e44edbe375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training process in a for loop with learning rate drop every 25 epoches.\n",
        "\n",
        "hist = model.fit(x_train, y_train,\n",
        "                                 batch_size=batch_size,\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    epochs=maxepoches,\n",
        "                    validation_data=(x_test, y_test),callbacks=[reduce_lr],verbose=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0302s vs `on_train_batch_end` time: 0.0487s). Check your callbacks.\n",
            "390/390 - 25s - loss: 20.0790 - accuracy: 0.0227 - val_loss: 15.1080 - val_accuracy: 0.0161\n",
            "Epoch 2/200\n",
            "390/390 - 25s - loss: 11.5330 - accuracy: 0.0443 - val_loss: 9.3000 - val_accuracy: 0.0245\n",
            "Epoch 3/200\n",
            "390/390 - 26s - loss: 7.4772 - accuracy: 0.0606 - val_loss: 6.6533 - val_accuracy: 0.0393\n",
            "Epoch 4/200\n",
            "390/390 - 26s - loss: 5.5961 - accuracy: 0.0791 - val_loss: 5.4546 - val_accuracy: 0.0538\n",
            "Epoch 5/200\n",
            "390/390 - 26s - loss: 4.6679 - accuracy: 0.1048 - val_loss: 5.0431 - val_accuracy: 0.0740\n",
            "Epoch 6/200\n",
            "390/390 - 26s - loss: 4.2325 - accuracy: 0.1340 - val_loss: 4.1745 - val_accuracy: 0.1336\n",
            "Epoch 7/200\n",
            "390/390 - 26s - loss: 3.9682 - accuracy: 0.1662 - val_loss: 4.2084 - val_accuracy: 0.1517\n",
            "Epoch 8/200\n",
            "390/390 - 26s - loss: 3.8259 - accuracy: 0.1957 - val_loss: 3.9617 - val_accuracy: 0.1973\n",
            "Epoch 9/200\n",
            "390/390 - 26s - loss: 3.7149 - accuracy: 0.2272 - val_loss: 4.1863 - val_accuracy: 0.1793\n",
            "Epoch 10/200\n",
            "390/390 - 26s - loss: 3.6742 - accuracy: 0.2531 - val_loss: 3.6480 - val_accuracy: 0.2735\n",
            "Epoch 11/200\n",
            "390/390 - 27s - loss: 3.6432 - accuracy: 0.2742 - val_loss: 3.8031 - val_accuracy: 0.2582\n",
            "Epoch 12/200\n",
            "390/390 - 27s - loss: 3.6190 - accuracy: 0.2935 - val_loss: 3.7927 - val_accuracy: 0.2728\n",
            "Epoch 13/200\n",
            "390/390 - 27s - loss: 3.6154 - accuracy: 0.3126 - val_loss: 4.0185 - val_accuracy: 0.2665\n",
            "Epoch 14/200\n",
            "390/390 - 27s - loss: 3.6335 - accuracy: 0.3246 - val_loss: 3.9006 - val_accuracy: 0.3164\n",
            "Epoch 15/200\n",
            "390/390 - 27s - loss: 3.6550 - accuracy: 0.3386 - val_loss: 3.8308 - val_accuracy: 0.3176\n",
            "Epoch 16/200\n",
            "390/390 - 27s - loss: 3.6717 - accuracy: 0.3490 - val_loss: 3.7129 - val_accuracy: 0.3565\n",
            "Epoch 17/200\n",
            "390/390 - 27s - loss: 3.6971 - accuracy: 0.3565 - val_loss: 3.8447 - val_accuracy: 0.3433\n",
            "Epoch 18/200\n",
            "390/390 - 27s - loss: 3.7369 - accuracy: 0.3619 - val_loss: 4.0164 - val_accuracy: 0.3268\n",
            "Epoch 19/200\n",
            "390/390 - 27s - loss: 3.7301 - accuracy: 0.3710 - val_loss: 3.9512 - val_accuracy: 0.3424\n",
            "Epoch 20/200\n",
            "390/390 - 27s - loss: 3.7733 - accuracy: 0.3762 - val_loss: 3.9252 - val_accuracy: 0.3635\n",
            "Epoch 21/200\n",
            "390/390 - 27s - loss: 3.3890 - accuracy: 0.4468 - val_loss: 3.4745 - val_accuracy: 0.4149\n",
            "Epoch 22/200\n",
            "390/390 - 27s - loss: 3.2026 - accuracy: 0.4633 - val_loss: 3.3903 - val_accuracy: 0.4247\n",
            "Epoch 23/200\n",
            "390/390 - 27s - loss: 3.1688 - accuracy: 0.4672 - val_loss: 3.7138 - val_accuracy: 0.3750\n",
            "Epoch 24/200\n",
            "390/390 - 27s - loss: 3.1800 - accuracy: 0.4736 - val_loss: 3.6912 - val_accuracy: 0.4071\n",
            "Epoch 25/200\n",
            "390/390 - 27s - loss: 3.1824 - accuracy: 0.4770 - val_loss: 3.4830 - val_accuracy: 0.4313\n",
            "Epoch 26/200\n",
            "390/390 - 27s - loss: 3.2184 - accuracy: 0.4825 - val_loss: 3.9693 - val_accuracy: 0.3523\n",
            "Epoch 27/200\n",
            "390/390 - 27s - loss: 3.2344 - accuracy: 0.4888 - val_loss: 3.5227 - val_accuracy: 0.4442\n",
            "Epoch 28/200\n",
            "390/390 - 27s - loss: 3.2702 - accuracy: 0.4941 - val_loss: 3.6133 - val_accuracy: 0.4309\n",
            "Epoch 29/200\n",
            "390/390 - 27s - loss: 3.2632 - accuracy: 0.4991 - val_loss: 3.6872 - val_accuracy: 0.4365\n",
            "Epoch 30/200\n",
            "390/390 - 27s - loss: 3.2677 - accuracy: 0.5045 - val_loss: 3.8559 - val_accuracy: 0.4210\n",
            "Epoch 31/200\n",
            "390/390 - 27s - loss: 3.2965 - accuracy: 0.5072 - val_loss: 3.7940 - val_accuracy: 0.4278\n",
            "Epoch 32/200\n",
            "390/390 - 27s - loss: 3.2957 - accuracy: 0.5142 - val_loss: 3.7458 - val_accuracy: 0.4333\n",
            "Epoch 33/200\n",
            "390/390 - 27s - loss: 3.3138 - accuracy: 0.5121 - val_loss: 3.7734 - val_accuracy: 0.4382\n",
            "Epoch 34/200\n",
            "390/390 - 27s - loss: 3.3189 - accuracy: 0.5170 - val_loss: 3.7450 - val_accuracy: 0.4380\n",
            "Epoch 35/200\n",
            "390/390 - 27s - loss: 3.3487 - accuracy: 0.5189 - val_loss: 3.6707 - val_accuracy: 0.4557\n",
            "Epoch 36/200\n",
            "390/390 - 27s - loss: 3.3597 - accuracy: 0.5183 - val_loss: 3.5921 - val_accuracy: 0.4874\n",
            "Epoch 37/200\n",
            "390/390 - 27s - loss: 3.3758 - accuracy: 0.5216 - val_loss: 3.7447 - val_accuracy: 0.4632\n",
            "Epoch 38/200\n",
            "390/390 - 27s - loss: 3.4027 - accuracy: 0.5208 - val_loss: 3.6812 - val_accuracy: 0.4699\n",
            "Epoch 39/200\n",
            "390/390 - 27s - loss: 3.4063 - accuracy: 0.5239 - val_loss: 3.6986 - val_accuracy: 0.4760\n",
            "Epoch 40/200\n",
            "390/390 - 27s - loss: 3.3986 - accuracy: 0.5277 - val_loss: 3.8749 - val_accuracy: 0.4392\n",
            "Epoch 41/200\n",
            "390/390 - 27s - loss: 3.0691 - accuracy: 0.5940 - val_loss: 3.1728 - val_accuracy: 0.5576\n",
            "Epoch 42/200\n",
            "390/390 - 27s - loss: 2.8659 - accuracy: 0.6157 - val_loss: 3.1576 - val_accuracy: 0.5504\n",
            "Epoch 43/200\n",
            "390/390 - 27s - loss: 2.7833 - accuracy: 0.6211 - val_loss: 3.1173 - val_accuracy: 0.5539\n",
            "Epoch 44/200\n",
            "390/390 - 27s - loss: 2.7582 - accuracy: 0.6242 - val_loss: 3.2657 - val_accuracy: 0.5385\n",
            "Epoch 45/200\n",
            "390/390 - 27s - loss: 2.7548 - accuracy: 0.6243 - val_loss: 3.1689 - val_accuracy: 0.5365\n",
            "Epoch 46/200\n",
            "390/390 - 27s - loss: 2.7674 - accuracy: 0.6230 - val_loss: 3.5300 - val_accuracy: 0.4812\n",
            "Epoch 47/200\n",
            "390/390 - 27s - loss: 2.7646 - accuracy: 0.6249 - val_loss: 3.6811 - val_accuracy: 0.4670\n",
            "Epoch 48/200\n",
            "390/390 - 27s - loss: 2.7733 - accuracy: 0.6297 - val_loss: 3.2248 - val_accuracy: 0.5465\n",
            "Epoch 49/200\n",
            "390/390 - 27s - loss: 2.7829 - accuracy: 0.6329 - val_loss: 3.3246 - val_accuracy: 0.5352\n",
            "Epoch 50/200\n",
            "390/390 - 27s - loss: 2.8042 - accuracy: 0.6311 - val_loss: 3.1282 - val_accuracy: 0.5707\n",
            "Epoch 51/200\n",
            "390/390 - 27s - loss: 2.8242 - accuracy: 0.6322 - val_loss: 3.3002 - val_accuracy: 0.5456\n",
            "Epoch 52/200\n",
            "390/390 - 27s - loss: 2.8239 - accuracy: 0.6377 - val_loss: 3.3502 - val_accuracy: 0.5385\n",
            "Epoch 53/200\n",
            "390/390 - 27s - loss: 2.8449 - accuracy: 0.6388 - val_loss: 3.3328 - val_accuracy: 0.5503\n",
            "Epoch 54/200\n",
            "390/390 - 27s - loss: 2.8565 - accuracy: 0.6383 - val_loss: 3.2633 - val_accuracy: 0.5657\n",
            "Epoch 55/200\n",
            "390/390 - 27s - loss: 2.8598 - accuracy: 0.6444 - val_loss: 3.3478 - val_accuracy: 0.5484\n",
            "Epoch 56/200\n",
            "390/390 - 27s - loss: 2.8823 - accuracy: 0.6419 - val_loss: 3.4220 - val_accuracy: 0.5452\n",
            "Epoch 57/200\n",
            "390/390 - 27s - loss: 2.8892 - accuracy: 0.6440 - val_loss: 3.3972 - val_accuracy: 0.5568\n",
            "Epoch 58/200\n",
            "390/390 - 27s - loss: 2.8984 - accuracy: 0.6482 - val_loss: 3.3418 - val_accuracy: 0.5692\n",
            "Epoch 59/200\n",
            "390/390 - 27s - loss: 2.9089 - accuracy: 0.6511 - val_loss: 3.5208 - val_accuracy: 0.5421\n",
            "Epoch 60/200\n",
            "390/390 - 27s - loss: 2.9206 - accuracy: 0.6530 - val_loss: 3.4246 - val_accuracy: 0.5548\n",
            "Epoch 61/200\n",
            "390/390 - 27s - loss: 2.6588 - accuracy: 0.7092 - val_loss: 3.1472 - val_accuracy: 0.6105\n",
            "Epoch 62/200\n",
            "390/390 - 27s - loss: 2.4665 - accuracy: 0.7408 - val_loss: 3.0940 - val_accuracy: 0.6157\n",
            "Epoch 63/200\n",
            "390/390 - 27s - loss: 2.3975 - accuracy: 0.7459 - val_loss: 3.0986 - val_accuracy: 0.6082\n",
            "Epoch 64/200\n",
            "390/390 - 27s - loss: 2.3577 - accuracy: 0.7469 - val_loss: 3.1063 - val_accuracy: 0.6003\n",
            "Epoch 65/200\n",
            "390/390 - 27s - loss: 2.3249 - accuracy: 0.7504 - val_loss: 3.0697 - val_accuracy: 0.6134\n",
            "Epoch 66/200\n",
            "390/390 - 27s - loss: 2.3090 - accuracy: 0.7480 - val_loss: 3.1789 - val_accuracy: 0.5860\n",
            "Epoch 67/200\n",
            "390/390 - 27s - loss: 2.3150 - accuracy: 0.7465 - val_loss: 3.1117 - val_accuracy: 0.6059\n",
            "Epoch 68/200\n",
            "390/390 - 27s - loss: 2.3029 - accuracy: 0.7517 - val_loss: 3.1530 - val_accuracy: 0.5975\n",
            "Epoch 69/200\n",
            "390/390 - 27s - loss: 2.3125 - accuracy: 0.7494 - val_loss: 3.1154 - val_accuracy: 0.5989\n",
            "Epoch 70/200\n",
            "390/390 - 27s - loss: 2.3031 - accuracy: 0.7525 - val_loss: 3.1140 - val_accuracy: 0.6043\n",
            "Epoch 71/200\n",
            "390/390 - 27s - loss: 2.2901 - accuracy: 0.7559 - val_loss: 3.1959 - val_accuracy: 0.5916\n",
            "Epoch 72/200\n",
            "390/390 - 27s - loss: 2.3121 - accuracy: 0.7496 - val_loss: 3.1796 - val_accuracy: 0.5979\n",
            "Epoch 73/200\n",
            "390/390 - 27s - loss: 2.3070 - accuracy: 0.7564 - val_loss: 3.2182 - val_accuracy: 0.5923\n",
            "Epoch 74/200\n",
            "390/390 - 27s - loss: 2.3169 - accuracy: 0.7558 - val_loss: 3.2417 - val_accuracy: 0.5900\n",
            "Epoch 75/200\n",
            "390/390 - 27s - loss: 2.3129 - accuracy: 0.7589 - val_loss: 3.0686 - val_accuracy: 0.6200\n",
            "Epoch 76/200\n",
            "390/390 - 27s - loss: 2.3290 - accuracy: 0.7558 - val_loss: 3.3021 - val_accuracy: 0.5860\n",
            "Epoch 77/200\n",
            "390/390 - 27s - loss: 2.3277 - accuracy: 0.7617 - val_loss: 3.2868 - val_accuracy: 0.5878\n",
            "Epoch 78/200\n",
            "390/390 - 27s - loss: 2.3417 - accuracy: 0.7586 - val_loss: 3.3607 - val_accuracy: 0.5851\n",
            "Epoch 79/200\n",
            "390/390 - 27s - loss: 2.3679 - accuracy: 0.7561 - val_loss: 3.2641 - val_accuracy: 0.5976\n",
            "Epoch 80/200\n",
            "390/390 - 27s - loss: 2.3574 - accuracy: 0.7621 - val_loss: 3.2365 - val_accuracy: 0.6086\n",
            "Epoch 81/200\n",
            "390/390 - 27s - loss: 2.1671 - accuracy: 0.8087 - val_loss: 3.1198 - val_accuracy: 0.6272\n",
            "Epoch 82/200\n",
            "390/390 - 27s - loss: 2.0229 - accuracy: 0.8388 - val_loss: 3.0837 - val_accuracy: 0.6376\n",
            "Epoch 83/200\n",
            "390/390 - 27s - loss: 1.9646 - accuracy: 0.8420 - val_loss: 3.1132 - val_accuracy: 0.6329\n",
            "Epoch 84/200\n",
            "390/390 - 27s - loss: 1.9164 - accuracy: 0.8491 - val_loss: 3.1103 - val_accuracy: 0.6370\n",
            "Epoch 85/200\n",
            "390/390 - 27s - loss: 1.8824 - accuracy: 0.8535 - val_loss: 3.1152 - val_accuracy: 0.6273\n",
            "Epoch 86/200\n",
            "390/390 - 27s - loss: 1.8461 - accuracy: 0.8551 - val_loss: 3.0858 - val_accuracy: 0.6326\n",
            "Epoch 87/200\n",
            "390/390 - 27s - loss: 1.8370 - accuracy: 0.8537 - val_loss: 3.1295 - val_accuracy: 0.6303\n",
            "Epoch 88/200\n",
            "390/390 - 27s - loss: 1.8111 - accuracy: 0.8561 - val_loss: 3.2265 - val_accuracy: 0.6176\n",
            "Epoch 89/200\n",
            "390/390 - 27s - loss: 1.8073 - accuracy: 0.8547 - val_loss: 3.1304 - val_accuracy: 0.6164\n",
            "Epoch 90/200\n",
            "390/390 - 27s - loss: 1.7793 - accuracy: 0.8576 - val_loss: 3.1145 - val_accuracy: 0.6244\n",
            "Epoch 91/200\n",
            "390/390 - 27s - loss: 1.7826 - accuracy: 0.8559 - val_loss: 3.1580 - val_accuracy: 0.6221\n",
            "Epoch 92/200\n",
            "390/390 - 27s - loss: 1.7688 - accuracy: 0.8568 - val_loss: 3.0689 - val_accuracy: 0.6363\n",
            "Epoch 93/200\n",
            "390/390 - 27s - loss: 1.7595 - accuracy: 0.8587 - val_loss: 3.0722 - val_accuracy: 0.6308\n",
            "Epoch 94/200\n",
            "390/390 - 27s - loss: 1.7605 - accuracy: 0.8557 - val_loss: 3.0494 - val_accuracy: 0.6359\n",
            "Epoch 95/200\n",
            "390/390 - 27s - loss: 1.7553 - accuracy: 0.8556 - val_loss: 3.0468 - val_accuracy: 0.6318\n",
            "Epoch 96/200\n",
            "390/390 - 27s - loss: 1.7468 - accuracy: 0.8584 - val_loss: 3.1210 - val_accuracy: 0.6197\n",
            "Epoch 97/200\n",
            "390/390 - 27s - loss: 1.7474 - accuracy: 0.8581 - val_loss: 3.0936 - val_accuracy: 0.6281\n",
            "Epoch 98/200\n",
            "390/390 - 27s - loss: 1.7454 - accuracy: 0.8572 - val_loss: 3.0669 - val_accuracy: 0.6297\n",
            "Epoch 99/200\n",
            "390/390 - 27s - loss: 1.7427 - accuracy: 0.8562 - val_loss: 3.1366 - val_accuracy: 0.6198\n",
            "Epoch 100/200\n",
            "390/390 - 27s - loss: 1.7422 - accuracy: 0.8574 - val_loss: 3.1071 - val_accuracy: 0.6193\n",
            "Epoch 101/200\n",
            "390/390 - 27s - loss: 1.6289 - accuracy: 0.8871 - val_loss: 2.9296 - val_accuracy: 0.6532\n",
            "Epoch 102/200\n",
            "390/390 - 27s - loss: 1.5509 - accuracy: 0.9045 - val_loss: 2.9707 - val_accuracy: 0.6504\n",
            "Epoch 103/200\n",
            "390/390 - 27s - loss: 1.4953 - accuracy: 0.9159 - val_loss: 2.9745 - val_accuracy: 0.6538\n",
            "Epoch 104/200\n",
            "390/390 - 27s - loss: 1.4582 - accuracy: 0.9220 - val_loss: 3.0227 - val_accuracy: 0.6489\n",
            "Epoch 105/200\n",
            "390/390 - 27s - loss: 1.4266 - accuracy: 0.9261 - val_loss: 3.0082 - val_accuracy: 0.6581\n",
            "Epoch 106/200\n",
            "390/390 - 27s - loss: 1.4021 - accuracy: 0.9277 - val_loss: 3.0688 - val_accuracy: 0.6475\n",
            "Epoch 107/200\n",
            "390/390 - 27s - loss: 1.3878 - accuracy: 0.9289 - val_loss: 3.0408 - val_accuracy: 0.6477\n",
            "Epoch 108/200\n",
            "390/390 - 27s - loss: 1.3743 - accuracy: 0.9275 - val_loss: 3.0492 - val_accuracy: 0.6431\n",
            "Epoch 109/200\n",
            "390/390 - 27s - loss: 1.3561 - accuracy: 0.9296 - val_loss: 3.0394 - val_accuracy: 0.6541\n",
            "Epoch 110/200\n",
            "390/390 - 27s - loss: 1.3414 - accuracy: 0.9307 - val_loss: 3.0458 - val_accuracy: 0.6450\n",
            "Epoch 111/200\n",
            "390/390 - 27s - loss: 1.3277 - accuracy: 0.9305 - val_loss: 3.0230 - val_accuracy: 0.6491\n",
            "Epoch 112/200\n",
            "390/390 - 27s - loss: 1.3066 - accuracy: 0.9328 - val_loss: 3.0604 - val_accuracy: 0.6427\n",
            "Epoch 113/200\n",
            "390/390 - 27s - loss: 1.3072 - accuracy: 0.9294 - val_loss: 3.0201 - val_accuracy: 0.6440\n",
            "Epoch 114/200\n",
            "390/390 - 27s - loss: 1.2955 - accuracy: 0.9300 - val_loss: 2.9960 - val_accuracy: 0.6472\n",
            "Epoch 115/200\n",
            "390/390 - 27s - loss: 1.2876 - accuracy: 0.9289 - val_loss: 3.0234 - val_accuracy: 0.6482\n",
            "Epoch 116/200\n",
            "390/390 - 27s - loss: 1.2729 - accuracy: 0.9302 - val_loss: 3.0019 - val_accuracy: 0.6469\n",
            "Epoch 117/200\n",
            "390/390 - 27s - loss: 1.2614 - accuracy: 0.9312 - val_loss: 3.0170 - val_accuracy: 0.6430\n",
            "Epoch 118/200\n",
            "390/390 - 27s - loss: 1.2589 - accuracy: 0.9287 - val_loss: 3.0893 - val_accuracy: 0.6355\n",
            "Epoch 119/200\n",
            "390/390 - 27s - loss: 1.2568 - accuracy: 0.9274 - val_loss: 2.9548 - val_accuracy: 0.6521\n",
            "Epoch 120/200\n",
            "390/390 - 27s - loss: 1.2388 - accuracy: 0.9299 - val_loss: 2.9917 - val_accuracy: 0.6400\n",
            "Epoch 121/200\n",
            "390/390 - 27s - loss: 1.1936 - accuracy: 0.9428 - val_loss: 2.9389 - val_accuracy: 0.6537\n",
            "Epoch 122/200\n",
            "390/390 - 27s - loss: 1.1623 - accuracy: 0.9487 - val_loss: 2.9450 - val_accuracy: 0.6497\n",
            "Epoch 123/200\n",
            "390/390 - 27s - loss: 1.1326 - accuracy: 0.9554 - val_loss: 2.9194 - val_accuracy: 0.6576\n",
            "Epoch 124/200\n",
            "390/390 - 27s - loss: 1.1156 - accuracy: 0.9579 - val_loss: 2.9079 - val_accuracy: 0.6588\n",
            "Epoch 125/200\n",
            "390/390 - 27s - loss: 1.0999 - accuracy: 0.9607 - val_loss: 2.9496 - val_accuracy: 0.6551\n",
            "Epoch 126/200\n",
            "390/390 - 27s - loss: 1.0909 - accuracy: 0.9611 - val_loss: 2.9227 - val_accuracy: 0.6597\n",
            "Epoch 127/200\n",
            "390/390 - 27s - loss: 1.0770 - accuracy: 0.9617 - val_loss: 2.9455 - val_accuracy: 0.6572\n",
            "Epoch 128/200\n",
            "390/390 - 27s - loss: 1.0656 - accuracy: 0.9628 - val_loss: 2.9320 - val_accuracy: 0.6608\n",
            "Epoch 129/200\n",
            "390/390 - 27s - loss: 1.0545 - accuracy: 0.9648 - val_loss: 2.9312 - val_accuracy: 0.6615\n",
            "Epoch 130/200\n",
            "390/390 - 27s - loss: 1.0437 - accuracy: 0.9648 - val_loss: 2.9451 - val_accuracy: 0.6588\n",
            "Epoch 131/200\n",
            "390/390 - 27s - loss: 1.0377 - accuracy: 0.9651 - val_loss: 2.9759 - val_accuracy: 0.6552\n",
            "Epoch 132/200\n",
            "390/390 - 27s - loss: 1.0234 - accuracy: 0.9655 - val_loss: 2.9493 - val_accuracy: 0.6594\n",
            "Epoch 133/200\n",
            "390/390 - 27s - loss: 1.0162 - accuracy: 0.9670 - val_loss: 2.9395 - val_accuracy: 0.6594\n",
            "Epoch 134/200\n",
            "390/390 - 27s - loss: 1.0103 - accuracy: 0.9652 - val_loss: 2.9889 - val_accuracy: 0.6561\n",
            "Epoch 135/200\n",
            "390/390 - 27s - loss: 0.9935 - accuracy: 0.9683 - val_loss: 2.9492 - val_accuracy: 0.6571\n",
            "Epoch 136/200\n",
            "390/390 - 27s - loss: 0.9821 - accuracy: 0.9696 - val_loss: 2.9686 - val_accuracy: 0.6576\n",
            "Epoch 137/200\n",
            "390/390 - 27s - loss: 0.9775 - accuracy: 0.9688 - val_loss: 2.9405 - val_accuracy: 0.6564\n",
            "Epoch 138/200\n",
            "390/390 - 27s - loss: 0.9731 - accuracy: 0.9680 - val_loss: 2.9563 - val_accuracy: 0.6575\n",
            "Epoch 139/200\n",
            "390/390 - 27s - loss: 0.9664 - accuracy: 0.9675 - val_loss: 2.9285 - val_accuracy: 0.6584\n",
            "Epoch 140/200\n",
            "390/390 - 27s - loss: 0.9532 - accuracy: 0.9711 - val_loss: 2.9630 - val_accuracy: 0.6584\n",
            "Epoch 141/200\n",
            "390/390 - 27s - loss: 0.9386 - accuracy: 0.9724 - val_loss: 2.9013 - val_accuracy: 0.6655\n",
            "Epoch 142/200\n",
            "390/390 - 27s - loss: 0.9290 - accuracy: 0.9748 - val_loss: 2.8770 - val_accuracy: 0.6673\n",
            "Epoch 143/200\n",
            "390/390 - 27s - loss: 0.9138 - accuracy: 0.9772 - val_loss: 2.8727 - val_accuracy: 0.6678\n",
            "Epoch 144/200\n",
            "390/390 - 27s - loss: 0.9114 - accuracy: 0.9765 - val_loss: 2.8786 - val_accuracy: 0.6660\n",
            "Epoch 145/200\n",
            "390/390 - 27s - loss: 0.9050 - accuracy: 0.9768 - val_loss: 2.8868 - val_accuracy: 0.6654\n",
            "Epoch 146/200\n",
            "390/390 - 27s - loss: 0.8952 - accuracy: 0.9797 - val_loss: 2.8890 - val_accuracy: 0.6652\n",
            "Epoch 147/200\n",
            "390/390 - 27s - loss: 0.8925 - accuracy: 0.9780 - val_loss: 2.8720 - val_accuracy: 0.6665\n",
            "Epoch 148/200\n",
            "390/390 - 27s - loss: 0.8844 - accuracy: 0.9799 - val_loss: 2.8657 - val_accuracy: 0.6653\n",
            "Epoch 149/200\n",
            "390/390 - 27s - loss: 0.8806 - accuracy: 0.9795 - val_loss: 2.8874 - val_accuracy: 0.6675\n",
            "Epoch 150/200\n",
            "390/390 - 27s - loss: 0.8738 - accuracy: 0.9805 - val_loss: 2.8737 - val_accuracy: 0.6661\n",
            "Epoch 151/200\n",
            "390/390 - 27s - loss: 0.8688 - accuracy: 0.9795 - val_loss: 2.8694 - val_accuracy: 0.6674\n",
            "Epoch 152/200\n",
            "390/390 - 27s - loss: 0.8647 - accuracy: 0.9810 - val_loss: 2.8854 - val_accuracy: 0.6671\n",
            "Epoch 153/200\n",
            "390/390 - 27s - loss: 0.8589 - accuracy: 0.9820 - val_loss: 2.8756 - val_accuracy: 0.6661\n",
            "Epoch 154/200\n",
            "390/390 - 27s - loss: 0.8540 - accuracy: 0.9812 - val_loss: 2.8939 - val_accuracy: 0.6639\n",
            "Epoch 155/200\n",
            "390/390 - 27s - loss: 0.8495 - accuracy: 0.9815 - val_loss: 2.9150 - val_accuracy: 0.6620\n",
            "Epoch 156/200\n",
            "390/390 - 27s - loss: 0.8434 - accuracy: 0.9823 - val_loss: 2.8910 - val_accuracy: 0.6657\n",
            "Epoch 157/200\n",
            "390/390 - 27s - loss: 0.8403 - accuracy: 0.9817 - val_loss: 2.8759 - val_accuracy: 0.6675\n",
            "Epoch 158/200\n",
            "390/390 - 27s - loss: 0.8389 - accuracy: 0.9817 - val_loss: 2.9041 - val_accuracy: 0.6611\n",
            "Epoch 159/200\n",
            "390/390 - 27s - loss: 0.8341 - accuracy: 0.9815 - val_loss: 2.8887 - val_accuracy: 0.6645\n",
            "Epoch 160/200\n",
            "390/390 - 27s - loss: 0.8261 - accuracy: 0.9828 - val_loss: 2.8846 - val_accuracy: 0.6645\n",
            "Epoch 161/200\n",
            "390/390 - 27s - loss: 0.8183 - accuracy: 0.9839 - val_loss: 2.8693 - val_accuracy: 0.6668\n",
            "Epoch 162/200\n",
            "390/390 - 27s - loss: 0.8115 - accuracy: 0.9856 - val_loss: 2.8629 - val_accuracy: 0.6672\n",
            "Epoch 163/200\n",
            "390/390 - 27s - loss: 0.8114 - accuracy: 0.9853 - val_loss: 2.8716 - val_accuracy: 0.6663\n",
            "Epoch 164/200\n",
            "390/390 - 27s - loss: 0.8097 - accuracy: 0.9853 - val_loss: 2.8649 - val_accuracy: 0.6692\n",
            "Epoch 165/200\n",
            "390/390 - 27s - loss: 0.8082 - accuracy: 0.9851 - val_loss: 2.8527 - val_accuracy: 0.6675\n",
            "Epoch 166/200\n",
            "390/390 - 27s - loss: 0.8023 - accuracy: 0.9862 - val_loss: 2.8567 - val_accuracy: 0.6689\n",
            "Epoch 167/200\n",
            "390/390 - 27s - loss: 0.8021 - accuracy: 0.9855 - val_loss: 2.8699 - val_accuracy: 0.6665\n",
            "Epoch 168/200\n",
            "390/390 - 27s - loss: 0.7997 - accuracy: 0.9857 - val_loss: 2.8657 - val_accuracy: 0.6683\n",
            "Epoch 169/200\n",
            "390/390 - 27s - loss: 0.7950 - accuracy: 0.9859 - val_loss: 2.8596 - val_accuracy: 0.6682\n",
            "Epoch 170/200\n",
            "390/390 - 27s - loss: 0.7912 - accuracy: 0.9871 - val_loss: 2.8672 - val_accuracy: 0.6679\n",
            "Epoch 171/200\n",
            "390/390 - 27s - loss: 0.7911 - accuracy: 0.9863 - val_loss: 2.8589 - val_accuracy: 0.6680\n",
            "Epoch 172/200\n",
            "390/390 - 27s - loss: 0.7886 - accuracy: 0.9864 - val_loss: 2.8513 - val_accuracy: 0.6670\n",
            "Epoch 173/200\n",
            "390/390 - 27s - loss: 0.7875 - accuracy: 0.9860 - val_loss: 2.8480 - val_accuracy: 0.6684\n",
            "Epoch 174/200\n",
            "390/390 - 27s - loss: 0.7830 - accuracy: 0.9874 - val_loss: 2.8527 - val_accuracy: 0.6715\n",
            "Epoch 175/200\n",
            "390/390 - 27s - loss: 0.7800 - accuracy: 0.9873 - val_loss: 2.8379 - val_accuracy: 0.6704\n",
            "Epoch 176/200\n",
            "390/390 - 27s - loss: 0.7811 - accuracy: 0.9863 - val_loss: 2.8499 - val_accuracy: 0.6698\n",
            "Epoch 177/200\n",
            "390/390 - 27s - loss: 0.7762 - accuracy: 0.9876 - val_loss: 2.8592 - val_accuracy: 0.6677\n",
            "Epoch 178/200\n",
            "390/390 - 27s - loss: 0.7743 - accuracy: 0.9870 - val_loss: 2.8567 - val_accuracy: 0.6700\n",
            "Epoch 179/200\n",
            "390/390 - 27s - loss: 0.7723 - accuracy: 0.9871 - val_loss: 2.8561 - val_accuracy: 0.6682\n",
            "Epoch 180/200\n",
            "390/390 - 27s - loss: 0.7700 - accuracy: 0.9874 - val_loss: 2.8414 - val_accuracy: 0.6719\n",
            "Epoch 181/200\n",
            "390/390 - 27s - loss: 0.7665 - accuracy: 0.9877 - val_loss: 2.8553 - val_accuracy: 0.6696\n",
            "Epoch 182/200\n",
            "390/390 - 27s - loss: 0.7663 - accuracy: 0.9877 - val_loss: 2.8464 - val_accuracy: 0.6705\n",
            "Epoch 183/200\n",
            "390/390 - 27s - loss: 0.7654 - accuracy: 0.9874 - val_loss: 2.8422 - val_accuracy: 0.6712\n",
            "Epoch 184/200\n",
            "390/390 - 27s - loss: 0.7624 - accuracy: 0.9880 - val_loss: 2.8480 - val_accuracy: 0.6701\n",
            "Epoch 185/200\n",
            "390/390 - 27s - loss: 0.7614 - accuracy: 0.9881 - val_loss: 2.8495 - val_accuracy: 0.6695\n",
            "Epoch 186/200\n",
            "390/390 - 27s - loss: 0.7597 - accuracy: 0.9883 - val_loss: 2.8403 - val_accuracy: 0.6702\n",
            "Epoch 187/200\n",
            "390/390 - 27s - loss: 0.7606 - accuracy: 0.9880 - val_loss: 2.8430 - val_accuracy: 0.6706\n",
            "Epoch 188/200\n",
            "390/390 - 27s - loss: 0.7569 - accuracy: 0.9888 - val_loss: 2.8408 - val_accuracy: 0.6717\n",
            "Epoch 189/200\n",
            "390/390 - 27s - loss: 0.7566 - accuracy: 0.9886 - val_loss: 2.8474 - val_accuracy: 0.6712\n",
            "Epoch 190/200\n",
            "390/390 - 27s - loss: 0.7552 - accuracy: 0.9887 - val_loss: 2.8432 - val_accuracy: 0.6703\n",
            "Epoch 191/200\n",
            "390/390 - 27s - loss: 0.7522 - accuracy: 0.9892 - val_loss: 2.8359 - val_accuracy: 0.6727\n",
            "Epoch 192/200\n",
            "390/390 - 27s - loss: 0.7552 - accuracy: 0.9881 - val_loss: 2.8507 - val_accuracy: 0.6709\n",
            "Epoch 193/200\n",
            "390/390 - 27s - loss: 0.7534 - accuracy: 0.9889 - val_loss: 2.8488 - val_accuracy: 0.6707\n",
            "Epoch 194/200\n",
            "390/390 - 27s - loss: 0.7503 - accuracy: 0.9890 - val_loss: 2.8363 - val_accuracy: 0.6732\n",
            "Epoch 195/200\n",
            "390/390 - 27s - loss: 0.7477 - accuracy: 0.9892 - val_loss: 2.8453 - val_accuracy: 0.6691\n",
            "Epoch 196/200\n",
            "390/390 - 27s - loss: 0.7466 - accuracy: 0.9894 - val_loss: 2.8326 - val_accuracy: 0.6719\n",
            "Epoch 197/200\n",
            "390/390 - 27s - loss: 0.7444 - accuracy: 0.9896 - val_loss: 2.8388 - val_accuracy: 0.6705\n",
            "Epoch 198/200\n",
            "390/390 - 27s - loss: 0.7455 - accuracy: 0.9898 - val_loss: 2.8432 - val_accuracy: 0.6695\n",
            "Epoch 199/200\n",
            "390/390 - 27s - loss: 0.7409 - accuracy: 0.9903 - val_loss: 2.8467 - val_accuracy: 0.6711\n",
            "Epoch 200/200\n",
            "390/390 - 27s - loss: 0.7405 - accuracy: 0.9904 - val_loss: 2.8523 - val_accuracy: 0.6702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2sm2muGySgp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}