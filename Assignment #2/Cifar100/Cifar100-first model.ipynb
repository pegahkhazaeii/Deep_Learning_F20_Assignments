{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (48000, 32, 32, 3)\n",
      "Train labels shape:  (48000,)\n",
      "Validation data shape:  (2000, 32, 32, 3)\n",
      "Validation labels shape:  (2000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "#@title Manual Data Injection\n",
    "from six.moves import cPickle as pickle\n",
    "import platform\n",
    "import numpy as np\n",
    " \n",
    "def load_files(filenames):\n",
    "    data = np.array([])\n",
    "    labels = np.array([])\n",
    "    for name in filenames:\n",
    "        with open(name, 'rb') as f:\n",
    "            mydict = pickle.load(f, encoding='latin1')\n",
    "\n",
    "        # The labels have different names in the two datasets.\n",
    "        label_func = lambda x: np.array(x['fine_labels'], dtype='int32')\n",
    "        newlabels = label_func(mydict)\n",
    "        if data.size:\n",
    "            data = np.vstack([data, mydict['data']])\n",
    "            labels = np.hstack([labels, newlabels])\n",
    "        else:\n",
    "            data = mydict['data']\n",
    "            labels = newlabels\n",
    "    data = np.reshape(data, [-1, 3, 32, 32], order='C')\n",
    "    data = np.transpose(data, [0, 2, 3, 1])\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def load_CIFAR100(data_dir):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    train_files = ['train']\n",
    "    train_files = [os.path.join(data_dir, f) for f in train_files]\n",
    "    test_files = ['test']\n",
    "    test_files = [os.path.join(data_dir, f) for f in test_files]\n",
    "    num_classes = 100\n",
    "    train_data, train_labels = load_files(train_files)\n",
    "    test_data, test_labels = load_files(test_files)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    " \n",
    "def get_CIFAR100_data(val_size=2000):\n",
    "    # Load the raw CIFAR-100 data\n",
    "    cifar100_dir = r'C:\\Users\\Pegah Khazaie\\Desktop\\cifar-100-python'\n",
    "    x_train, y_train, x_test, y_test = load_CIFAR100(cifar100_dir)\n",
    "    # Subsample the data\n",
    " \n",
    "    x_train, x_val = np.split(x_train,\n",
    "                              [x_train.shape[0]-val_size])\n",
    "    y_train, y_val = np.split(y_train,\n",
    "                              [y_train.shape[0]-val_size])\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    " \n",
    "#     x_train /= 255\n",
    "#     x_val /= 255\n",
    "#     x_test /= 255\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    " \n",
    "# Invoke the above function to get our data.\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_CIFAR100_data()\n",
    " \n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import *\n",
    "from keras.preprocessing import image\n",
    "from keras import regularizers,optimizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch < 2:\n",
    "        lrate = 0.005\n",
    "    if epoch > 5:\n",
    "        lrate = 0.0001\n",
    "    return lrate\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Sequential()\n",
    "model.add(Conv2D(32,(2,2),padding='same',input_shape=(32,32,3),activation='elu'))\n",
    "model.add(MaxPool2D(2,2))    \n",
    "model.add(Conv2D(64, (2, 2), padding='same',activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.rmsprop(lr=0.001, decay=0.00005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=1, mode='min', verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pegah Khazaie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 38400 samples, validate on 9600 samples\n",
      "Epoch 1/10\n",
      "38400/38400 [==============================] - 135s 4ms/step - loss: 0.0553 - accuracy: 0.9900 - val_loss: 0.0530 - val_accuracy: 0.9900\n",
      "Epoch 2/10\n",
      "38400/38400 [==============================] - 135s 4ms/step - loss: 0.0539 - accuracy: 0.9900 - val_loss: 0.0522 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "38400/38400 [==============================] - 129s 3ms/step - loss: 0.0534 - accuracy: 0.9900 - val_loss: 0.0512 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "38400/38400 [==============================] - 131s 3ms/step - loss: 0.0526 - accuracy: 0.9900 - val_loss: 0.0503 - val_accuracy: 0.9900\n",
      "Epoch 5/10\n",
      "38400/38400 [==============================] - 133s 3ms/step - loss: 0.0520 - accuracy: 0.9900 - val_loss: 0.0510 - val_accuracy: 0.9900\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23c36efb5c8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,epochs=10,validation_split=0.2,verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 923us/step\n"
     ]
    }
   ],
   "source": [
    "res_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_acc: 0.9899795055389404\n"
     ]
    }
   ],
   "source": [
    "print(\"res_acc:\",res_acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
