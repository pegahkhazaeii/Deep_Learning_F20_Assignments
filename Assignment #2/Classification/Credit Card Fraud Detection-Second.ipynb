{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJwyzFx5J8bu"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG1gXHh6KE2t",
        "outputId": "33f88350-c58c-41ab-ad30-27e3f161f233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nPKDq17KKya",
        "outputId": "b3af3b14-9b0b-4c88-95d4-62cfbabad440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Deep Learning\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1.jpg\t\t\t  fashion-mnist_train.csv   Untitled4.ipynb\n",
            " 2.jpg\t\t\t  Housing.CSV\t\t    Untitled5.ipynb\n",
            " 3.jpg\t\t\t  insurance.csv\t\t    Untitled6.ipynb\n",
            "'Assignment #4.ipynb'\t  Untitled\t\t    Untitled7.ipynb\n",
            "'Assignment #5.ipynb'\t  Untitled0.ipynb\t    Untitled8.ipynb\n",
            " cifar-10-batches-py\t  Untitled1.ipynb\t    Untitled9.ipynb\n",
            " creditcard.csv\t\t  Untitled2.ipynb\t    win2.xls\n",
            " fashion-mnist_test.csv   Untitled3.ipynb\t    wine1.xls\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZPpy-ujKhWn"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yumxE6A-KpU3"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/My Drive/Deep Learning/creditcard.csv\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUD23ZVoLlM2",
        "outputId": "fc093ec9-7b01-43a3-992f-5db5be06e781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVPIX1wBMJ5T"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sclaer = StandardScaler()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7V24DGaMima",
        "outputId": "05963166-4390-4ec5-a982-840349acce93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "X_data = dataset.iloc[:,0:-1].values\n",
        "X_data[0:2]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00, -1.35980713e+00, -7.27811733e-02,\n",
              "         2.53634674e+00,  1.37815522e+00, -3.38320770e-01,\n",
              "         4.62387778e-01,  2.39598554e-01,  9.86979013e-02,\n",
              "         3.63786970e-01,  9.07941720e-02, -5.51599533e-01,\n",
              "        -6.17800856e-01, -9.91389847e-01, -3.11169354e-01,\n",
              "         1.46817697e+00, -4.70400525e-01,  2.07971242e-01,\n",
              "         2.57905802e-02,  4.03992960e-01,  2.51412098e-01,\n",
              "        -1.83067779e-02,  2.77837576e-01, -1.10473910e-01,\n",
              "         6.69280749e-02,  1.28539358e-01, -1.89114844e-01,\n",
              "         1.33558377e-01, -2.10530535e-02,  1.49620000e+02],\n",
              "       [ 0.00000000e+00,  1.19185711e+00,  2.66150712e-01,\n",
              "         1.66480113e-01,  4.48154078e-01,  6.00176493e-02,\n",
              "        -8.23608088e-02, -7.88029833e-02,  8.51016549e-02,\n",
              "        -2.55425128e-01, -1.66974414e-01,  1.61272666e+00,\n",
              "         1.06523531e+00,  4.89095016e-01, -1.43772296e-01,\n",
              "         6.35558093e-01,  4.63917041e-01, -1.14804663e-01,\n",
              "        -1.83361270e-01, -1.45783041e-01, -6.90831352e-02,\n",
              "        -2.25775248e-01, -6.38671953e-01,  1.01288021e-01,\n",
              "        -3.39846476e-01,  1.67170404e-01,  1.25894532e-01,\n",
              "        -8.98309914e-03,  1.47241692e-02,  2.69000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCwdnW4oMnEQ",
        "outputId": "138bfdb9-0507-4e8c-ef14-8460e36a6936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y_data = dataset.iloc[:,-1].values\n",
        "Y_data[0:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiQpYvJUM2O1",
        "outputId": "d435788b-4871-4cf8-92fa-ae750b82d89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "unique , counts = np.unique(Y_data,return_counts = True)\n",
        "print(unique,counts)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1] [284315    492]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tou8iEB5M5mg",
        "outputId": "adca6641-9724-40c7-81c7-be3220373f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "X_data = sclaer.fit_transform(X_data)\n",
        "X_data[0:2]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.99658302, -0.69424232, -0.04407492,  1.6727735 ,  0.97336551,\n",
              "        -0.24511658,  0.34706795,  0.19367894,  0.08263728,  0.33112778,\n",
              "         0.08338555, -0.54040704, -0.61829572, -0.99609892, -0.32461019,\n",
              "         1.60401384, -0.53683287,  0.24486345,  0.03076993,  0.49628203,\n",
              "         0.32611802, -0.02492336,  0.38285444, -0.17691133,  0.11050692,\n",
              "         0.24658544, -0.39217043,  0.33089162, -0.06378115,  0.24496426],\n",
              "       [-1.99658302,  0.60849633,  0.16117592,  0.1097971 ,  0.31652293,\n",
              "         0.04348335, -0.06181997, -0.06370021,  0.07125348, -0.23249419,\n",
              "        -0.15334963,  1.58000285,  1.06608857,  0.4914182 , -0.14998248,\n",
              "         0.69436042,  0.52943375, -0.13516997, -0.21876258, -0.17908605,\n",
              "        -0.08961086, -0.3073768 , -0.88007675,  0.16220118, -0.56113055,\n",
              "         0.3206939 ,  0.26106948, -0.02225568,  0.04460752, -0.34247454]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsRZXuOGM8Y4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X_data,Y_data,test_size=0.3)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br_ijokTM-oS"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqhJDeDxNBbF"
      },
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Dense(40 , input_dim = 30 , activation = 'relu'))\n",
        "classifier.add(Dense(30 , input_dim = 40 , activation = 'relu'))\n",
        "classifier.add(Dense(20 , input_dim = 30 , activation = 'relu'))\n",
        "classifier.add(Dense(10 , input_dim = 20 , activation = 'relu'))\n",
        "classifier.add(Dense(6 , input_dim = 10 , activation = 'relu'))\n",
        "classifier.add(Dense(4 , input_dim = 6 , activation = 'relu'))\n",
        "classifier.add(Dense(1, input_dim = 4 , activation = 'sigmoid'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-S-wbCNNDb8"
      },
      "source": [
        "classifier.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSRbbFjBNF6F",
        "outputId": "82cc9c5f-6a32-46bd-fca0-7020aaa9d855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier.fit( x_train , y_train , epochs = 200 , batch_size = 500 )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.6057 - accuracy: 0.9651\n",
            "Epoch 2/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.9993\n",
            "Epoch 3/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.9994\n",
            "Epoch 4/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.9994\n",
            "Epoch 5/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9994\n",
            "Epoch 6/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.9994\n",
            "Epoch 7/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.1353 - accuracy: 0.9994\n",
            "Epoch 8/200\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.1099 - accuracy: 0.9994\n",
            "Epoch 9/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9994\n",
            "Epoch 10/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9994\n",
            "Epoch 11/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9995\n",
            "Epoch 12/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0514 - accuracy: 0.9995\n",
            "Epoch 13/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.9995\n",
            "Epoch 14/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0363 - accuracy: 0.9995\n",
            "Epoch 15/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9995\n",
            "Epoch 16/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0261 - accuracy: 0.9995\n",
            "Epoch 17/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9995\n",
            "Epoch 18/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9995\n",
            "Epoch 19/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0164 - accuracy: 0.9995\n",
            "Epoch 20/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0141 - accuracy: 0.9995\n",
            "Epoch 21/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0124 - accuracy: 0.9995\n",
            "Epoch 22/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9996\n",
            "Epoch 23/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9995\n",
            "Epoch 24/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9995\n",
            "Epoch 25/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9996\n",
            "Epoch 26/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0064 - accuracy: 0.9996\n",
            "Epoch 27/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9996\n",
            "Epoch 28/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9996\n",
            "Epoch 29/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9996\n",
            "Epoch 30/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9996\n",
            "Epoch 31/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9996\n",
            "Epoch 32/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9996\n",
            "Epoch 33/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 0.9997\n",
            "Epoch 34/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9997\n",
            "Epoch 35/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9997\n",
            "Epoch 36/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9996\n",
            "Epoch 37/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
            "Epoch 38/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9997\n",
            "Epoch 39/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9997\n",
            "Epoch 40/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9996\n",
            "Epoch 41/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9997\n",
            "Epoch 42/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 43/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 44/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0022 - accuracy: 0.9996\n",
            "Epoch 45/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 46/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 47/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 48/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 49/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 50/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 51/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 52/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 53/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 54/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 55/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 56/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 57/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 58/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 59/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 60/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 61/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 62/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 63/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 64/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 65/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 66/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 67/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 68/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 69/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 70/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 71/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 72/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0022 - accuracy: 0.9997\n",
            "Epoch 73/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 74/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 75/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 76/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 77/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 78/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 79/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 80/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 81/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 82/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 83/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 84/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 85/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 86/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 87/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 88/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 89/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 90/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 91/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 92/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 93/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 94/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 95/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 96/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 97/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 98/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 99/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 100/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 101/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 102/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 103/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 104/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 105/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 106/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 107/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 108/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 109/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 110/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 111/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 112/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 113/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 114/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 115/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 116/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 117/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 118/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 119/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 120/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 121/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 122/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 123/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 124/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 125/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 126/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 127/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 128/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 129/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 130/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 131/200\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 132/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 133/200\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 134/200\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 135/200\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 136/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 137/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 138/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 139/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 140/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 141/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 142/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 143/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 144/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 145/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 146/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 147/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 148/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 149/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 150/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 151/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 152/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 153/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 154/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 155/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 156/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 157/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 158/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 159/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 160/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 161/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 162/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 163/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 164/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 165/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 166/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 167/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 168/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 169/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 170/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 171/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 172/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 173/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 174/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 175/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 176/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 177/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 178/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 179/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 180/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 181/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 182/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 183/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 184/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 185/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 186/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 187/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 188/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 189/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 190/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 191/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 192/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 193/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 194/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 195/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 196/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 197/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 198/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 199/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 200/200\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc58a52ddd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEa_CKlTNH9A",
        "outputId": "200977f9-9e50-4995-c89a-431ea2fe6da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "classifier.evaluate(x_test,y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2671/2671 [==============================] - 2s 861us/step - loss: 0.0037 - accuracy: 0.9995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0037326994352042675, 0.9995201230049133]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69TZh-aJN0o9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}