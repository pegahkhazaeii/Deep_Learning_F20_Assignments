{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(r\"C:\\Users\\Pegah Khazaie\\Desktop\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'M':1,'B':0}\n",
    "dataset = dataset.replace(d) #replace M/B with 0 or 1 for the neural net classification\n",
    "dataset = dataset.drop(['Unnamed: 32'],axis=1) #remove column 32 - unknown purpose\n",
    "dataset = dataset.drop(['id'],axis=1) #remove the id - not needed for the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = dataset.drop(['diagnosis'],axis=1) \n",
    "X = np.array(dataset_temp).T \n",
    "Y = np.array(dataset['diagnosis']).T \n",
    "Y = Y.reshape(1,569)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's normalized our feature vector.  We will force the mean of each column to 0, and divide by the maximum\n",
    "X_mean = np.mean(X,axis=1,keepdims=True) #Find the mean of each feature\n",
    "X_max = np.max(X,axis=1,keepdims=True) #Find the maximum of each feature\n",
    "X_normalized = (X-X_mean)/(X_max) #Normalizing our dataset by subtracting the mean and dividing by the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_normalized[:,:380]\n",
    "Y_train = Y[:,:380]\n",
    "\n",
    "#We will take the remaining 189 for our cross-validation set\n",
    "X_cv = X_normalized[:,381:]\n",
    "Y_cv = Y[:,381:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now define our sigmoid function to be used in the output layer of our neural network (L3)\n",
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now define our tanh(x) function to be used in hidden layers of our neural network (L1, L2)\n",
    "#Note that the tanh(x) function allows better centering of data than the sigmoid function.  This is why it will be used in our hidden layers.\n",
    "\n",
    "def tanh(z):\n",
    "    s = (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's define our forward propogation function.\n",
    "def forward_prop(X,W1,W2,W3,b1,b2,b3):\n",
    "    \n",
    "    #First layer forward propogation\n",
    "    Z1 = np.dot(W1,X)\n",
    "    A1 = tanh(Z1 + b1)\n",
    "    #Second layer forward propogation\n",
    "    Z2 = np.dot(W2,A1)\n",
    "    A2 = tanh(Z2 + b2)\n",
    "    #Third layer forward propogation\n",
    "    Z3 = np.dot(W3,A2)\n",
    "    A3 = sigmoid(Z3 + b3) #A3 will produce our probability vector\n",
    "    \n",
    "    cache = {    \n",
    "                  \"Z1\": Z1,\n",
    "                  \"A1\": A1,\n",
    "                  \"Z2\": Z2,\n",
    "                  \"A2\": A2,\n",
    "                  \"Z3\": Z3,\n",
    "                  \"A3\": A3\n",
    "            }\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will perform gradient descent for our neural network in the following steps:\n",
    "#1) Start by randomly initializing our weight and intercept parameters\n",
    "#2) Run forward propogation through our neural network\n",
    "#3) Calculate the derivatives of our weights and intercept parameters via back propogation\n",
    "#4) Refine our parameters using derivatives from (3)\n",
    "#5) Reiterate 1 - 4 \n",
    "\n",
    "def gradient_descent(iterations,X,Y,alpha):\n",
    "    \n",
    "    #Randomly initialized our parameters before running the algorithm\n",
    "    W1 = np.random.randn(3,30)*0.01\n",
    "    b1 = np.random.rand(3,1)\n",
    "    W2 = np.random.randn(2,3)*0.01\n",
    "    b2 = np.random.rand(2,1)\n",
    "    W3 = np.random.rand(1,2)*0.01\n",
    "    b3 = np.random.rand(1,1)\n",
    "    dummy,m = X.shape\n",
    "    \n",
    "    caches = [] #we will store our cost at each iteration in this array\n",
    "    count_vector = [] #We will store our iteration count in this array\n",
    "    count = 0\n",
    "    \n",
    "    for i in range (1,iterations):\n",
    "        \n",
    "            count = count + 1\n",
    "            \n",
    "            count_vector.append(count)\n",
    "        \n",
    "            params = forward_prop(X,W1,W2,W3,b1,b2,b3) #forward propogation using our parameters\n",
    "            \n",
    "            #Define our values to be used in back propogation using the dictionary of values created from running forward_prop\n",
    "            Z1 = params['Z1']\n",
    "            Z2 = params['Z2']\n",
    "            Z3 = params['Z3']\n",
    "            A1 = params['A1']\n",
    "            A2 = params['A2']\n",
    "            A3 = params['A3']\n",
    "            \n",
    "            #Define our cost function, append the cost of each iteration to caches\n",
    "            cost = -(1 / m)*np.sum(np.multiply(Y,np.log(A3)) + np.multiply((1-Y),np.log(1-A3)))\n",
    "            caches.append(cost)\n",
    "            \n",
    "            #Back propogation for layer 3\n",
    "            dA3 = -Y/A3 + (1-Y)/(1-A3)\n",
    "            dZ3 = dA3 * sigmoid(Z3)*(1-sigmoid(Z3))\n",
    "            dW3 = (1 / m)*np.dot(dZ3,A2.T)\n",
    "            db3 = (1 / m)*np.sum(dZ3,axis=1,keepdims=True)\n",
    "            \n",
    "            #Back propogation for layer 2\n",
    "            dA2 = np.dot(W3.T,dZ3)\n",
    "            dZ2 = dA2*(1-np.power(tanh(Z2),2))\n",
    "            dW2 = (1 / m)*np.dot(dZ2,A1.T)\n",
    "            db2 = (1 / m)*np.sum(dZ2,axis=1,keepdims=True)\n",
    "            \n",
    "            #Back propogation for layer 1\n",
    "            dA1 = np.dot(W2.T,dZ2)\n",
    "            dZ1 = dA1*(1-np.power(tanh(Z1),2))\n",
    "            dW1 = (1 / m)*np.dot(dZ1,X.T)\n",
    "            db1 = (1 / m)*np.sum(dZ1,axis=1,keepdims=True)\n",
    "            \n",
    "            #Redefine our weight parameters using the derivatives calculated in back propogation\n",
    "            W1 = W1 - alpha*dW1\n",
    "            W2 = W2 - alpha*dW2\n",
    "            W3 = W3 - alpha*dW3\n",
    "            \n",
    "            #Redefine our weight parameters using the derivatives calculated in back propogation\n",
    "            b1 = b1 - alpha*db1\n",
    "            b2 = b2 - alpha*db2\n",
    "            b3 = b3 - alpha*db3\n",
    "        \n",
    "    return W1,W2,W3,b1,b2,b3,count_vector,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets see if our algorithm is working.  We should see a declining learning curve with iteration, which eventually flatterns out\n",
    "#This will help us determine the appropriate number of iterations to run to determine the appropriate parameters\n",
    "#Note: we will use a learning rate of 0.5 for now\n",
    "\n",
    "W1,W2,W3,b1,b2,b3,count,caches = gradient_descent(1000,X_cv,Y_cv,0.5)\n",
    "\n",
    "plt.plot(count,caches,label='Cost')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "plt.title(\"Cost vs. Iteration\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,Y,iterations,alpha,X_train,Y_train):\n",
    "\n",
    "    W1,W2,W3,b1,b2,b3,count,caches = gradient_descent(iterations,X_train,Y_train,alpha)\n",
    "    \n",
    "    Z1 = np.dot(W1,X)\n",
    "    A1 = tanh(Z1 + b1)\n",
    "    Z2 = np.dot(W2,A1)\n",
    "    A2 = tanh(Z2 + b2)\n",
    "    Z3 = np.dot(W3,A2)\n",
    "    A3 = sigmoid(Z3 + b3)\n",
    "    \n",
    "    dummy,m = A3.shape\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        Y_prediction[0, i] = 1 if A3[0, i] > 0.5 else 0\n",
    "        \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.21052631578948 %\n",
      "Cross validation accuracy: 96.80851063829788 %\n"
     ]
    }
   ],
   "source": [
    "#Lets see how accurate the predictions made by our neural network are compared to the training set and cross validation set\n",
    "print(\"Train accuracy: {} %\".format(100 - np.mean(np.abs(predict(X_train,Y_train,1000,0.5,X_train,Y_train) - Y_train)) * 100))\n",
    "print(\"Cross validation accuracy: {} %\".format(100 - np.mean(np.abs(predict(X_cv,Y_cv,1000,0.5,X_train,Y_train) - Y_cv)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
