{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle\n",
    "import os\n",
    "import platform\n",
    "from subprocess import check_output\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "def load_pickle(f):\n",
    "    version = platform.python_version_tuple()\n",
    "    if version[0] == '2':\n",
    "        return  pickle.load(f)\n",
    "    elif version[0] == '3':\n",
    "        return  pickle.load(f, encoding='latin1')\n",
    "    raise ValueError(\"invalid python version: {}\".format(version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = load_pickle(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000,3072)\n",
    "        Y = np.array(Y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = r'C:\\Users\\Pegah Khazaie\\Desktop\\cifar-10-batches-py/'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    x_train = X_train.astype('float32')\n",
    "    x_test = X_test.astype('float32')\n",
    "\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    return x_train, y_train, X_val, y_val, x_test, y_test\n",
    "# Invoke the above function to get our data.\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3072)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 3072)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_id = 3\n",
    "sample_id = 7000\n",
    "display_stats(r'C:\\Users\\Pegah Khazaie\\Desktop\\cifar-10-batches-py/', batch_id, sample_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data(r'C:\\Users\\Pegah Khazaie\\Desktop\\cifar-10-batches-py/', normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y =  tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "keep_probability = 0.7\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logits = conv_net(x, keep_prob)\n",
    "model = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1756 Validation Accuracy: 0.192400\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.8448 Validation Accuracy: 0.238600\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.5965 Validation Accuracy: 0.285000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.5628 Validation Accuracy: 0.364400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.3624 Validation Accuracy: 0.393000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.4931 Validation Accuracy: 0.384200\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.3099 Validation Accuracy: 0.489800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.0453 Validation Accuracy: 0.509400\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.0830 Validation Accuracy: 0.562000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     0.9156 Validation Accuracy: 0.597600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     0.8750 Validation Accuracy: 0.615000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     0.6971 Validation Accuracy: 0.624200\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.6684 Validation Accuracy: 0.628600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     0.6558 Validation Accuracy: 0.662000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     0.5040 Validation Accuracy: 0.659200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     0.5805 Validation Accuracy: 0.660600\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.5345 Validation Accuracy: 0.654200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.3747 Validation Accuracy: 0.680200\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.3172 Validation Accuracy: 0.696800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.2474 Validation Accuracy: 0.685000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     0.3755 Validation Accuracy: 0.699800\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.2748 Validation Accuracy: 0.692400\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.1725 Validation Accuracy: 0.712000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.1433 Validation Accuracy: 0.703800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.1238 Validation Accuracy: 0.691800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.2472 Validation Accuracy: 0.695200\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.1112 Validation Accuracy: 0.706600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.1302 Validation Accuracy: 0.662200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.0918 Validation Accuracy: 0.704400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.0772 Validation Accuracy: 0.681800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.1315 Validation Accuracy: 0.716400\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.0368 Validation Accuracy: 0.716200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.0372 Validation Accuracy: 0.722400\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.0440 Validation Accuracy: 0.717800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.0341 Validation Accuracy: 0.743200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.0398 Validation Accuracy: 0.724600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.0371 Validation Accuracy: 0.722400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.0236 Validation Accuracy: 0.726600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.0426 Validation Accuracy: 0.714400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.0188 Validation Accuracy: 0.737200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.0187 Validation Accuracy: 0.737600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.0174 Validation Accuracy: 0.726800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.0229 Validation Accuracy: 0.719200\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.0116 Validation Accuracy: 0.735400\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.0086 Validation Accuracy: 0.736000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.0204 Validation Accuracy: 0.728600\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.0246 Validation Accuracy: 0.721800\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.0126 Validation Accuracy: 0.721200\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.0086 Validation Accuracy: 0.723600\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.0285 Validation Accuracy: 0.717600\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
